[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "all_posts_categorized.html",
    "href": "all_posts_categorized.html",
    "title": "Browse all recipes",
    "section": "",
    "text": "Python\nMostly pandas and matplotlib tricks.\n\n  \n    \n      \n        \n          \n            Create small-multiples charts from scratch in Matplotlib \n            \n              (Nov 7, 2022)\n            \n          \n           matplotlib, tutorial \n        \n      \n      \n        \n          \n            Creating colormaps in matplotlib \n            \n              (Aug 2, 2022)\n            \n          \n           cheatsheet, matplotlib \n        \n      \n      \n        \n          \n            Customizing the legend \n            \n              (Sep 27, 2022)\n            \n          \n           matplotlib \n        \n      \n      \n        \n          \n            Dealing with messy CSVs \n            \n              (Sep 16, 2022)\n            \n          \n           pandas \n        \n      \n      \n        \n          \n            Generate dictionaries from dataframes \n            \n              (Sep 16, 2022)\n            \n          \n           pandas \n        \n      \n      \n        \n          \n            Generating random days between two dates \n            \n              (Jul 30, 2022)\n            \n          \n           cheatsheet, pandas \n        \n      \n      \n        \n          \n            How to draw things in figure coordinates in MPL using IPython/Jupyter \n            \n              (Nov 26, 2022)\n            \n          \n           matplotlib, jupyter \n        \n      \n      \n        \n          \n            Installing geopandas on Windows \n            \n              (May 26, 2023)\n            \n          \n           pandas, geodata \n        \n      \n      \n        \n          \n            Saving a chart as a numpy array and warping it using skimage \n            \n              (Aug 3, 2022)\n            \n          \n           cheatsheet, matplotlib, numpy \n        \n      \n      \n        \n          \n            Skipping empty csv rows \n            \n              (Aug 4, 2022)\n            \n          \n           cheatsheet, pandas \n        \n      \n      \n        \n          \n            Tick formatting recipes \n            \n              (Sep 21, 2022)\n            \n          \n           matplotlib \n        \n      \n      \n        \n          \n            Using fontprops \n            \n              (Sep 27, 2022)\n            \n          \n           matplotlib \n        \n      \n      \n        \n          \n            Various Matplotlib resources \n            \n              (Aug 4, 2022)\n            \n          \n           matplotlib \n        \n      \n      \n        \n          \n            Various Pandas resources \n            \n              (Aug 4, 2022)\n            \n          \n           pandas \n        \n      \n      \n        \n          \n            Watermarks, footnotes and other annotations \n            \n              (Sep 27, 2022)\n            \n          \n           matplotlib \n        \n      \n      \n        \n          \n            Weekday names in pandas \n            \n              (Oct 8, 2022)\n            \n          \n           pandas, datetime \n        \n      \n      \n        \n          \n            Working with datetimes \n            \n              (Jul 26, 2022)\n            \n          \n           cheatsheet, pandas \n        \n      \n    \n  \n\nNo matching items\n\n\n  \n\n\n\n\nQuarto\n\n  \n    \n      \n        \n          \n            Add traffic analytics to your quarto blog \n            \n              (Nov 9, 2022)\n            \n          \n           quarto \n        \n      \n      \n        \n          \n            Coupling Python and Observable using ojs_define() \n            \n              (Jul 30, 2022)\n            \n          \n           quarto \n        \n      \n      \n        \n          \n            Fix the `quarto publish gh-pages` error on windows \n            \n              (Aug 8, 2022)\n            \n          \n           quarto, git \n        \n      \n      \n        \n          \n            Quarto how-to \n            \n              (Jul 29, 2022)\n            \n          \n           cheatsheet \n        \n      \n      \n        \n          \n            Various resources about quarto \n            \n              (Aug 1, 2022)\n            \n          \n           quarto \n        \n      \n    \n  \n\nNo matching items\n\n\n\n\nVarious\n\n\n  \n    \n      \n        \n          \n            Doing things with conda environments \n            \n              (Oct 8, 2022)\n            \n          \n           python, conda \n        \n      \n      \n        \n          \n            Poetry tips and tricks \n            \n              (Aug 18, 2022)\n            \n          \n           cheatsheet, poetry \n        \n      \n      \n        \n          \n            Style a list element to look like a table \n            \n              (Aug 5, 2022)\n            \n          \n           css \n        \n      \n      \n        \n          \n            Useful git stuff \n            \n              (Jul 26, 2022)\n            \n          \n           cheatsheet, git \n        \n      \n      \n        \n          \n            Writing EJS templates \n            \n              (Aug 5, 2022)\n            \n          \n           ejs, quarto, javascript \n        \n      \n    \n  \n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data visualization recipesin Python",
    "section": "",
    "text": "Welcome! I am Teresa, data scientist focused on data visualization.\nHere I collect useful code snippets, recipes and tips for visualizing and analysing data with Python.\nYou may want to check out my awesome matplotlib repository where I collect tutorials and other resources about Matplotlib.\n\nLatest recipes\n\n  \n    \n      \n        \n          \n            Installing geopandas on Windows \n            \n              (May 26, 2023)\n            \n          \n           pandas, geodata \n        \n      \n      \n        \n          \n            How to draw things in figure coordinates in MPL using IPython/Jupyter \n            \n              (Nov 26, 2022)\n            \n          \n           matplotlib, jupyter \n        \n      \n      \n        \n          \n            Add traffic analytics to your quarto blog \n            \n              (Nov 9, 2022)\n            \n          \n           quarto \n        \n      \n      \n        \n          \n            Create small-multiples charts from scratch in Matplotlib \n            \n              (Nov 7, 2022)\n            \n          \n           matplotlib, tutorial \n        \n      \n      \n        \n          \n            Doing things with conda environments \n            \n              (Oct 8, 2022)\n            \n          \n           python, conda \n        \n      \n      \n        \n          \n            Weekday names in pandas \n            \n              (Oct 8, 2022)\n            \n          \n           pandas, datetime \n        \n      \n      \n        \n          \n            Using fontprops \n            \n              (Sep 27, 2022)\n            \n          \n           matplotlib \n        \n      \n      \n        \n          \n            Customizing the legend \n            \n              (Sep 27, 2022)\n            \n          \n           matplotlib \n        \n      \n    \n  \n\nNo matching items\n\n\n  \n\n\n\nBrowse all recipes…"
  },
  {
    "objectID": "posts/mpl/colormaps.html",
    "href": "posts/mpl/colormaps.html",
    "title": "Creating colormaps in matplotlib",
    "section": "",
    "text": "import matplotlib.pyplot as plt\n%matplotlib inline"
  },
  {
    "objectID": "posts/mpl/colormaps.html#create-colormap-from-a-list-of-colors",
    "href": "posts/mpl/colormaps.html#create-colormap-from-a-list-of-colors",
    "title": "Creating colormaps in matplotlib",
    "section": "Create colormap from a list of colors",
    "text": "Create colormap from a list of colors\n\nfrom matplotlib.colors import LinearSegmentedColormap\ncustom_cmap = LinearSegmentedColormap.from_list(name=\"my_cmap\", colors=[\"green\", \"black\", \"purple\"])\ncustom_cmap\n\nmy_cmap  underbad over \n\n\n\nfrom matplotlib.colors import ListedColormap, BoundaryNorm\n\ncustom_cmap2 = ListedColormap(name=\"another_cmap\", colors=['green', 'black', 'purple'])\n\ncustom_cmap2\n\nanother_cmap  underbad over \n\n\n\n# ListedColormap with norm: \nnorm2 = BoundaryNorm([-1, -0.15, 0.15, 1], custom_cmap2.N) \n# BoundaryNorm maps values to INTEGERS instead of floats 0..1\nprint(norm2(0.5))\n\nf, ax = plt.subplots()\np = ax.imshow([[-0.5, -0.1], [0,0.1], [0.8,0.5]], cmap=custom_cmap2, norm=norm2)\nf.colorbar(mappable=p, spacing='proportional')\n\n2\n\n\n&lt;matplotlib.colorbar.Colorbar at 0x1d1859349d0&gt;"
  },
  {
    "objectID": "posts/mpl/colormaps.html#merge-2-colormaps",
    "href": "posts/mpl/colormaps.html#merge-2-colormaps",
    "title": "Creating colormaps in matplotlib",
    "section": "Merge 2 colormaps",
    "text": "Merge 2 colormaps\n\ncmap1 = LinearSegmentedColormap.from_list(name=\"cmap1\", colors=[\"green\", \"black\", \"purple\"])\ncmap2 = LinearSegmentedColormap.from_list(name=\"cmap2\", colors=[\"blue\", \"yellow\", \"orange\"])\n\nWith sharp edge:\n\nimport numpy as np\ncolors_cmap1 = cmap1(np.linspace(0, 1, 100))\ncolors_cmap2 = cmap2(np.linspace(0, 1, 200))\nall_colors = np.vstack((colors_cmap1, colors_cmap2))\n\ncmap_merged = LinearSegmentedColormap.from_list('merged',all_colors)\n\ncmap_merged\n\nmerged  underbad over \n\n\nWith smooth transition:\n\ncolors_cmap1 = cmap1(np.linspace(0, 1, 3))\ncolors_cmap2 = cmap2(np.linspace(0, 1, 6))\nall_colors = np.vstack((colors_cmap1, colors_cmap2))\n\ncmap_merged = LinearSegmentedColormap.from_list('merged',all_colors)\n\ncmap_merged\n\nmerged  underbad over"
  },
  {
    "objectID": "posts/mpl/figure_coordinates_inline_tight.html",
    "href": "posts/mpl/figure_coordinates_inline_tight.html",
    "title": "How to draw things in figure coordinates in MPL using IPython/Jupyter",
    "section": "",
    "text": "I only wanted to draw a frame around my Matplotlib figure. Instead, I discovered that Ipython matplotlib-inline backend and the layout parameter called from within the MPL code override each other in a confusing way. Also, the layout = tight does not lead to the same result when called from the inline backend and when called from MPL.\n\nimport matplotlib.pyplot as plt \nfrom matplotlib.patches import Rectangle \nfrom matplotlib.lines import Line2D\n\nimport matplotlib as mpl \nprint(\"MPL: {}\".format(mpl.__version__))\n\nimport IPython as Ipt\nprint(\"IPython: {}\".format(Ipt.__version__))\n\nMPL: 3.6.1\nIPython: 8.2.0\n\n\nThere are at least 2 ways to draw a frame around the whole chart:\n\nmodify the figure appearance using f.set_edgecolor() + f.set_linewidth() (default linewidth is zero)\ncreate a new rectangle and add it to the figure children.\n\nThis is how you can add rectangles to the figure itself: to use the figure coordinates, use the transform parameter. After creating a new rectangle object, add it to f.patches.\n\nf, ax = plt.subplots()\n\n# rectangle covering the bottom left quarter of the figure: \nar = Rectangle(xy=(0,0), width=0.5, height=0.5, \n               transform=f.transFigure, \n               facecolor='forestgreen')\nf.patches.extend([ar])\n\n\n\n\nHowever, the longer I tried to reconcile the two functionalities, the longer I got confused. Let me show you.\nLet’s define a function that will create an example chart. To be able to distinguish between different artists on the chart, I will:\n\ncolor the chart background as yellow and draw a green frame around it\nadd an extra red rectangle that should cover the whole figure (from (0,0) to (1,1) in figure coordinates)\nadd a blue line that should go across the whole figure (from (0,0) to (1,1) in figure coordinates)\n\n\n\ndef ugly_chart(layout_kw={}):\ndef ugly_chart(layout_kw={}):\n    \n    # initialize the figure with a default layout \n    f, ax = plt.subplots(figsize=(5,3), dpi=100, **layout_kw)\n    \n    # style a patch which is automatically created with the figure - it is a yellow rectangle that serves as a figure background \n    f.set_edgecolor('forestgreen')\n    f.set_linewidth(2)\n    f.set_facecolor('cornsilk')\n\n    # add a rectangle with a red frame that should extend from (0,0) to (1,1) in figure coordinates\n    ar = Rectangle(xy=(0,0), width=1, height=1, transform=f.transFigure,  \n                   facecolor=\"none\", \n                   linewidth=5, edgecolor='red', linestyle=':')\n    f.patches.extend([ar])\n\n    # add a line that should extend from (0,0) to (1,1) in figure coordinates\n    l1 = Line2D([0, 1], [0, 1], transform=f.transFigure, color='dodgerblue')\n    f.lines.extend([l1])\n    \n    print(\"bbox of the yellow background patch: {}\".format(f.get_children()[0].get_bbox()))\n    print(\"bbox of the red dotted rectangle box: {}\".format(ar.get_bbox()))\n    \n    return f, ax\n\n\nLet’s inspect the chart that has been drawn as a result. The red and yellow rectangles do not overlap, although their bboxes are technically the same and should correspond to the same artist and same coordinate system!\n\nugly_chart();\n\nbbox of the yellow background patch: Bbox(x0=0.0, y0=0.0, x1=1.0, y1=1.0)\nbbox of the red dotted rectangle box: Bbox(x0=0.0, y0=0.0, x1=1.0, y1=1.0)\n\n\n\n\n\nAlso notice how the right green border got cut out of the image. The bottom green border is visible only partially (I believe this is because the bottom border is 1px off, and right border 2px off).\nNow we can preview what we would have obtained if we saved the figure to png. Here let’s stream the MPL output to the buffer and display the buffer. Since the original function will also show us the chart, let’s modify the original chart after we exported it, so that we can distinguish the two:\n\nfrom io import BytesIO\nf, ax = ugly_chart();\n\n# export to buffer \nbuf = BytesIO()\nf.savefig(buf, format=\"png\")\n\n# modify and show the original chart \nax.set_title('original chart')\n\nbbox of the yellow background patch: Bbox(x0=0.0, y0=0.0, x1=1.0, y1=1.0)\nbbox of the red dotted rectangle box: Bbox(x0=0.0, y0=0.0, x1=1.0, y1=1.0)\n\n\nText(0.5, 1.0, 'original chart')\n\n\n\n\n\nAnd the exported chart would look like this:\n\n# display the buffer - output of savefig \nfrom IPython.display import Image \nImage(buf.getvalue())\n\n\n\n\nWTF? It seems that the savefig does everything properly! But I mostly work with Jupyter interactively, so I do need the inline backend to work properly. So what is happening?\nAfter some digging, it turns out that the reason for this discrepancy is the Ipython inline backend configuration. Ipython silently sets all the plots to be rendered in tight layout. We can modify them with a magic command. However, keep in mind this will modify the MPL behavior globally for all the plots in the current session:\n\n%config InlineBackend.print_figure_kwargs = {'bbox_inches':None}\nugly_chart();\n\nbbox of the yellow background patch: Bbox(x0=0.0, y0=0.0, x1=1.0, y1=1.0)\nbbox of the red dotted rectangle box: Bbox(x0=0.0, y0=0.0, x1=1.0, y1=1.0)\n\n\n\n\n\nSo we finally got what we wanted. For sanity, le’t see what happens when we go back to the original setting:\n\n%config InlineBackend.print_figure_kwargs = {'bbox_inches':'tight'}\nugly_chart();\n\nbbox of the yellow background patch: Bbox(x0=0.0, y0=0.0, x1=1.0, y1=1.0)\nbbox of the red dotted rectangle box: Bbox(x0=0.0, y0=0.0, x1=1.0, y1=1.0)\n\n\n\n\n\nIt works as expected: I got back the initial (incorrect) result.\nNow we can pass some keywords to the plt.subplots() inside the ugly_chart(). Let’s try to override the layout setting that the IPython has set, by calling the layout parameter while initializing a figure:\n\n%config InlineBackend.print_figure_kwargs = {'bbox_inches':'tight'}\nugly_chart({'layout': None});\n\nbbox of the yellow background patch: Bbox(x0=0.0, y0=0.0, x1=1.0, y1=1.0)\nbbox of the red dotted rectangle box: Bbox(x0=0.0, y0=0.0, x1=1.0, y1=1.0)\n\n\n\n\n\n\n%config InlineBackend.print_figure_kwargs = {'bbox_inches':'tight'}\nugly_chart({'layout': 'tight'});\n\nbbox of the yellow background patch: Bbox(x0=0.0, y0=0.0, x1=1.0, y1=1.0)\nbbox of the red dotted rectangle box: Bbox(x0=0.0, y0=0.0, x1=1.0, y1=1.0)\n\n\n\n\n\nIt seems that the layout parameter passed to the keyword was ignored! WTF?\nAnd the other way round?\n\n%config InlineBackend.print_figure_kwargs = {'bbox_inches':None}\nugly_chart({'layout': 'tight'});\n\nbbox of the yellow background patch: Bbox(x0=0.0, y0=0.0, x1=1.0, y1=1.0)\nbbox of the red dotted rectangle box: Bbox(x0=0.0, y0=0.0, x1=1.0, y1=1.0)\n\n\n\n\n\n\n%config InlineBackend.print_figure_kwargs = {'bbox_inches':None}\nugly_chart({'layout': 'none'});\n\nbbox of the yellow background patch: Bbox(x0=0.0, y0=0.0, x1=1.0, y1=1.0)\nbbox of the red dotted rectangle box: Bbox(x0=0.0, y0=0.0, x1=1.0, y1=1.0)\n\n\n\n\n\nSo it looks like the IPython finally lets MPL use the layout parameter if the Inline backend layout is set to None.\nAnyway. Happy charting, everyone."
  },
  {
    "objectID": "posts/mpl/font_magic.html",
    "href": "posts/mpl/font_magic.html",
    "title": "Using fontprops",
    "section": "",
    "text": "import matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/mpl/font_magic.html#use-fontprops-with-various-entities",
    "href": "posts/mpl/font_magic.html#use-fontprops-with-various-entities",
    "title": "Using fontprops",
    "section": "Use fontprops with various entities",
    "text": "Use fontprops with various entities\nDeclare fontprops:\nimport matplotlib as mpl\n\ncustom_font = mpl.font_manager.FontProperties(\n    family='Verdana', style='italic', size=14\n    )\nax.annotate('Something interesting here', \n            xy = (0.5,0.5), xycoords=ax,\n            fontproperties=custom_font,)\n\nf.suptitle('Nice title', \n            fontproperties=custom_font, )\n\nfor tick in ax.get_yticklabels():\n    tick.set_font_properties(custom_font)\n\nax.legend(handles=handles, prop=custom_font)"
  },
  {
    "objectID": "posts/mpl/font_magic.html#use-local-ttf-file-as-fontprops",
    "href": "posts/mpl/font_magic.html#use-local-ttf-file-as-fontprops",
    "title": "Using fontprops",
    "section": "Use local ttf file as fontprops",
    "text": "Use local ttf file as fontprops\nfrom pathlib import Path\n\ntitle_font = mpl.font_manager.FontProperties(\n            fname=Path(\"./Barlow/Barlow-Bold.ttf\"), size=20)"
  },
  {
    "objectID": "posts/mpl/legend.html",
    "href": "posts/mpl/legend.html",
    "title": "Customizing the legend",
    "section": "",
    "text": "Modified on: 2022-08-08, 2022-09-27"
  },
  {
    "objectID": "posts/mpl/legend.html#move-the-legend-to-top-right-corner-outside-of-the-chart-no-border",
    "href": "posts/mpl/legend.html#move-the-legend-to-top-right-corner-outside-of-the-chart-no-border",
    "title": "Customizing the legend",
    "section": "Move the legend to top right corner outside of the chart, no border",
    "text": "Move the legend to top right corner outside of the chart, no border\nax.legend(handles, labels, \n          bbox_to_anchor=[1.05,1], loc='upper left', \n          edgecolor='w', facecolor='none',\n          borderpad=0, borderaxespad=0)"
  },
  {
    "objectID": "posts/mpl/legend.html#place-the-legend-between-two-topmost-horizontal-gridlines",
    "href": "posts/mpl/legend.html#place-the-legend-between-two-topmost-horizontal-gridlines",
    "title": "Customizing the legend",
    "section": "Place the legend between two topmost horizontal gridlines",
    "text": "Place the legend between two topmost horizontal gridlines\n\nh = ax.plot(...)\n\ntop_tick = np.mean([ax.get_yticks()[-2], ax.get_yticks()[-3]])\nleft_tick = ax.get_xlim()[0]\n\nl = ax.legend(handles=[h],  \n    bbox_to_anchor=[left_tick,top_tick], bbox_transform=ax.transData, loc='center left', \n    borderpad=0.0, borderaxespad=0.5, \n    )"
  },
  {
    "objectID": "posts/mpl/mpl_numpy_warping.html",
    "href": "posts/mpl/mpl_numpy_warping.html",
    "title": "Saving a chart as a numpy array and warping it using skimage",
    "section": "",
    "text": "Sometimes we may want to create an image with plotting API of matplotlib, but then apply a transform that only works for numpy arrays (for example, skimage’s warps). This is how you do it:\n\nimport matplotlib.pyplot as plt \nimport numpy as np\n%matplotlib inline\n\nLet’s generate an example chart:\n\nx = [1,2,3]\nbars = [10,15,12]\n\nf, ax = plt.subplots(dpi=100)\n# when using plt.subplots, the canvas and renderer get created automatically \nax.bar(x, bars);\n\n\n\n\n\nExport the figure to a numpy array\nMethod 1 src\n\ns, (width, height) = f.canvas.print_to_buffer()\nrgba = np.frombuffer(s, np.uint8).reshape((height, width, 4))\nplt.imshow(rgba, aspect='equal');\n\n\n\n\n\nprint(type(rgba))\nprint(rgba.shape)\n\n&lt;class 'numpy.ndarray'&gt;\n(400, 600, 4)\n\n\nMethod 2 src\n\nrgba = np.asarray(f.canvas.buffer_rgba())\nplt.imshow(rgba);\n\n\n\n\n\nprint(type(rgba))\nprint(rgba.shape)\n\n&lt;class 'numpy.ndarray'&gt;\n(400, 600, 4)\n\n\n\n\nRemove the alpha channel in a numpy array (RGBA-&gt;RGB)\nTo remove the alpha channel it’s enough to run: src\n\nrgb = rgba[:,:,:3]\n\nThe resulting chart is the same (our transparency is anyway white)\n\nplt.imshow(rgb);\n\n\n\n\nBoth methods respect the dpi set when creating the figure using plt.subplots\n\n\nWarping images using skimage\nNow we can warp the image:\n\nfrom skimage.transform import swirl\n\nswirled = swirl(rgb, rotation=0, strength=30, radius=120)\n\n\nf, ax = plt.subplots(ncols = 2, figsize=(10,4))\n\nax[0].imshow(rgb, aspect='equal')\nax[0].set_title('original')\n\nax[1].imshow(swirled, aspect='equal')\nax[1].set_title('warped')\n\n[a.axis('off') for a in ax];\n\n\n\n\nMore on skimage transforms: https://scikit-image.org/docs/stable/api/skimage.transform.html"
  },
  {
    "objectID": "posts/mpl/mpl_small-multiples_ziplongest.html",
    "href": "posts/mpl/mpl_small-multiples_ziplongest.html",
    "title": "Create small-multiples charts from scratch in Matplotlib",
    "section": "",
    "text": "how to loop over axes and data\nhow to display axis labels only in some axes\nhow to store styles in dictionaries\nhow to adjust tick frequency\nhow to create a custom legend\nhow to pass properties inside a charting function\n\nSmall multiples is an extremely helpful technique in data visualization. See below how a small multiples chart can be done using seaborn’s relplot. How could we make such a chart from scratch in MPL, adjusted to our needs?\n\nimport seaborn as sns\n\nflights = sns.load_dataset(\"flights\")\n\n# Plot each year's time series in its own facet\ng = sns.relplot(\n    data=flights,\n    x=\"month\", y=\"passengers\", col=\"year\", hue=\"year\",\n    kind=\"line\", palette=\"crest\", linewidth=4, zorder=5,\n    col_wrap=5, height=2, aspect=1.5, legend=False,\n)\n\n# Iterate over each subplot to customize further\nfor year, ax in g.axes_dict.items():\n    \n    # Plot every year's time series in the background\n    sns.lineplot(\n        data=flights, x=\"month\", y=\"passengers\", units=\"year\",\n        estimator=None, color=\".7\", linewidth=1, ax=ax,\n    )\n\ng.tight_layout()"
  },
  {
    "objectID": "posts/mpl/mpl_small-multiples_ziplongest.html#in-this-tutorial",
    "href": "posts/mpl/mpl_small-multiples_ziplongest.html#in-this-tutorial",
    "title": "Create small-multiples charts from scratch in Matplotlib",
    "section": "",
    "text": "how to loop over axes and data\nhow to display axis labels only in some axes\nhow to store styles in dictionaries\nhow to adjust tick frequency\nhow to create a custom legend\nhow to pass properties inside a charting function\n\nSmall multiples is an extremely helpful technique in data visualization. See below how a small multiples chart can be done using seaborn’s relplot. How could we make such a chart from scratch in MPL, adjusted to our needs?\n\nimport seaborn as sns\n\nflights = sns.load_dataset(\"flights\")\n\n# Plot each year's time series in its own facet\ng = sns.relplot(\n    data=flights,\n    x=\"month\", y=\"passengers\", col=\"year\", hue=\"year\",\n    kind=\"line\", palette=\"crest\", linewidth=4, zorder=5,\n    col_wrap=5, height=2, aspect=1.5, legend=False,\n)\n\n# Iterate over each subplot to customize further\nfor year, ax in g.axes_dict.items():\n    \n    # Plot every year's time series in the background\n    sns.lineplot(\n        data=flights, x=\"month\", y=\"passengers\", units=\"year\",\n        estimator=None, color=\".7\", linewidth=1, ax=ax,\n    )\n\ng.tight_layout()"
  },
  {
    "objectID": "posts/mpl/mpl_small-multiples_ziplongest.html#step-1-read-and-pre-transform-the-data",
    "href": "posts/mpl/mpl_small-multiples_ziplongest.html#step-1-read-and-pre-transform-the-data",
    "title": "Create small-multiples charts from scratch in Matplotlib",
    "section": "Step 1: read and pre-transform the data",
    "text": "Step 1: read and pre-transform the data\nLet’s read in dummy data and preprocess the datetimes, so that we can easily plot:\n\nfrom seaborn import load_dataset\nimport matplotlib.pyplot as plt \nimport pandas as pd \nimport numpy as np\n\ndf = load_dataset('flights')\ndf['m'] = df['month'].cat.codes.apply(lambda x: x+1)\ndf = df.sort_values(by=['year','m'])"
  },
  {
    "objectID": "posts/mpl/mpl_small-multiples_ziplongest.html#step-2-create-a-small-multiples-skeleton",
    "href": "posts/mpl/mpl_small-multiples_ziplongest.html#step-2-create-a-small-multiples-skeleton",
    "title": "Create small-multiples charts from scratch in Matplotlib",
    "section": "Step 2: create a small-multiples skeleton",
    "text": "Step 2: create a small-multiples skeleton\nWe want to create a small multiples chart, one chart per year.\nLet’s start from defining the rows and columns in the grid manually. We can use plt.subplots() and then iterate over the axes and the sub-dataframe for each axes. For this, we’re going to zip the axes and the keys used to sub-sample the dataframe.\n\nf, axes = plt.subplots(ncols=5, nrows=3, sharex=True, sharey=True)\n\nfor chosen, ax in zip(df['year'].unique(), axes.ravel()): \n    tmp_df = df[df['year']==chosen]\n    ax.plot(tmp_df['m'], tmp_df['passengers'], )\n\n\n\n\nBummer: zip will stop evaluating the moment the shorter list is exhausted.\nHowever, we can use a zip_longest function from itertools which will iterate until it exhausts the longer list. If we don’t provide a fillvalue to it, it will produce None once the shorter iterable has been exhausted. E.g.\n\nfrom itertools import zip_longest\n\n\nfor first, second in zip_longest(range(3), range(5)):\n    print(first, second)\n\n0 0\n1 1\n2 2\nNone 3\nNone 4\n\n\nWe need to generate more or equal axes than the number of charts we effectively expect (i.e. in our example, the number of available years). Then whenever we get None for the year, we can remove the axis from the figure:\n\nf, axes = plt.subplots(ncols=5, nrows=3, sharex=True, sharey=True)\n\nfor chosen, ax in zip_longest(df['year'].unique(), axes.ravel()): \n    if chosen is not None:\n        tmp_df = df[df['year']==chosen]\n        ax.plot(tmp_df['m'], tmp_df['passengers'], )\n    else: \n#         ax.axis('off')\n        ax.remove()\n\n\n\n\nLooks good!\nOnly the last adjustment: until now we have defined the number of charts by hand. Let’s only define the number of columns and let the script handle the relevant number of rows. Also, let’s not hardcode our column name, but rather store it in a variable:\n\ncol = 'year'\nnum_cols = 5\n\nnum_rows = (df[col].nunique() // num_cols) + 1\n\nf, axes = plt.subplots(ncols=num_cols, nrows=num_rows, sharex=True, sharey=True)\n\nfor chosen, ax in zip_longest(df[col].unique(), axes.ravel()): \n    if chosen is not None:\n        tmp_df = df[df[col]==chosen]\n        ax.plot(tmp_df['m'], tmp_df['passengers'], )\n    else: \n        ax.remove()"
  },
  {
    "objectID": "posts/mpl/mpl_small-multiples_ziplongest.html#step-3-add-missing-x-labels",
    "href": "posts/mpl/mpl_small-multiples_ziplongest.html#step-3-add-missing-x-labels",
    "title": "Create small-multiples charts from scratch in Matplotlib",
    "section": "Step 3: add missing x-labels",
    "text": "Step 3: add missing x-labels\nAnother problem has arisen. Because we are using sharex, sharey, the labels on the bottom line of charts are missing. Let’s find out which charts are on the bottom. We will create a bool table where we define 1 for the charts where we want to see the xlabels:\n\nremaining =  df[col].nunique() % num_cols \n\nis_xlabeled = np.zeros((num_rows, num_cols))\nis_xlabeled[-1][0:remaining] = 1\nis_xlabeled[-2][remaining:] = 1\n\n\nis_xlabeled\n\narray([[0., 0., 0., 0., 0.],\n       [0., 0., 1., 1., 1.],\n       [1., 1., 0., 0., 0.]])\n\n\nNow I can integrate it in my code by adding it to the zip_longest:\n\ncol = 'year'\nnum_cols = 5\n\nnum_charts = df[col].nunique()\n\nnum_rows = (num_charts // num_cols) + 1\nremaining =  num_charts % num_cols \n\nis_xlabeled = np.zeros((num_rows, num_cols))\nis_xlabeled[-1][0:remaining] = 1\nis_xlabeled[-2][remaining:] = 1\n\nf, axes = plt.subplots(ncols=num_cols, nrows=num_rows, sharex=True, sharey=True)\n\nfor chosen, ax, xlab in zip_longest(df[col].unique(), axes.ravel(), is_xlabeled.ravel()): \n    if chosen is not None:\n        tmp_df = df[df[col]==chosen]\n        ax.plot(tmp_df['m'], tmp_df['passengers'], )\n        if xlab: \n            ax.tick_params(axis='x', which='major', labelbottom=True)\n    else: \n        ax.remove()    \n\n\n\n\nHowever, I don’t like it for the readability. Also, maybe I don’t want to have this option hardcoded - it will be easier to parametrize it if I add the labels in a second loop. Here I can use a simple zip, because the is_xlabeled and axes have the same shapes.\n\ncol = 'year'\nnum_cols = 5\n\nnum_charts = df[col].nunique()\n\nnum_rows = (num_charts // num_cols) + 1\nremaining =  num_charts % num_cols \n\nis_xlabeled = np.zeros((num_rows, num_cols))\nis_xlabeled[-1][0:remaining] = 1\nis_xlabeled[-2][remaining:] = 1\n\nf, axes = plt.subplots(ncols=num_cols, nrows=num_rows, sharex=True, sharey=True)\n\nfor chosen, ax in zip_longest(df[col].unique(), axes.ravel()): \n    if chosen is not None:\n        tmp_df = df[df[col]==chosen]\n        ax.plot(tmp_df['m'], tmp_df['passengers'], )\n    else: \n        ax.remove()    \n\nfor xlab, ax in zip(is_xlabeled.ravel(), axes.ravel()): \n    if xlab: \n        ax.tick_params(axis='x', which='major', labelbottom=True)\n    \n\n\n\n\nLooks good!"
  },
  {
    "objectID": "posts/mpl/mpl_small-multiples_ziplongest.html#step-4-add-the-data-in-the-background",
    "href": "posts/mpl/mpl_small-multiples_ziplongest.html#step-4-add-the-data-in-the-background",
    "title": "Create small-multiples charts from scratch in Matplotlib",
    "section": "Step 4: add the data in the background",
    "text": "Step 4: add the data in the background\nFor this, let’s reshape our data. It’s going to be easier if we take advantage of the long-wide conversion and create a pivot table containing our data. Here we don’t need to do any aggregation, but this would be the first step in a data prep pipeline.\n\ndf_pivot = df.pivot(index='m', columns=col, values='passengers')\n\n\ndf_pivot\n\n\n\n\n\n\n\nyear\n1949\n1950\n1951\n1952\n1953\n1954\n1955\n1956\n1957\n1958\n1959\n1960\n\n\nm\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n112\n115\n145\n171\n196\n204\n242\n284\n315\n340\n360\n417\n\n\n2\n118\n126\n150\n180\n196\n188\n233\n277\n301\n318\n342\n391\n\n\n3\n132\n141\n178\n193\n236\n235\n267\n317\n356\n362\n406\n419\n\n\n4\n129\n135\n163\n181\n235\n227\n269\n313\n348\n348\n396\n461\n\n\n5\n121\n125\n172\n183\n229\n234\n270\n318\n355\n363\n420\n472\n\n\n6\n135\n149\n178\n218\n243\n264\n315\n374\n422\n435\n472\n535\n\n\n7\n148\n170\n199\n230\n264\n302\n364\n413\n465\n491\n548\n622\n\n\n8\n148\n170\n199\n242\n272\n293\n347\n405\n467\n505\n559\n606\n\n\n9\n136\n158\n184\n209\n237\n259\n312\n355\n404\n404\n463\n508\n\n\n10\n119\n133\n162\n191\n211\n229\n274\n306\n347\n359\n407\n461\n\n\n11\n104\n114\n146\n172\n180\n203\n237\n271\n305\n310\n362\n390\n\n\n12\n118\n140\n166\n194\n201\n229\n278\n306\n336\n337\n405\n432\n\n\n\n\n\n\n\nNow I can refactor the code: I can use df_pivot for getting my selected curve and for getting the background curves:\n\ncol = 'year'\nnum_cols = 5\n\nnum_charts = df[col].nunique()\n\nnum_rows = (num_charts // num_cols) + 1\nremaining =  num_charts % num_cols \n\nis_xlabeled = np.zeros((num_rows, num_cols))\nis_xlabeled[-1][0:remaining] = 1\nis_xlabeled[-2][remaining:] = 1\n\nf, axes = plt.subplots(ncols=num_cols, nrows=num_rows, sharex=True, sharey=True)\ndf_pivot = df.pivot(index='m', columns=col, values='passengers')\n\nfor chosen, ax in zip_longest(df[col].unique(), axes.ravel()): \n    if chosen is not None:\n        tmp_df = df_pivot[chosen]\n        ax.plot(tmp_df, color='orange', lw=2, zorder=99)\n        ax.plot(df_pivot, color='gray', lw=1, alpha=0.5)\n    else: \n        ax.remove()    \n\nfor xlab, ax in zip(is_xlabeled.ravel(), axes.ravel()): \n    if xlab: \n        ax.tick_params(axis='x', which='major', labelbottom=True)\n    \n\n\n\n\nLet’s move the styling outside of the loop where we plotting the dashboard. Maybe in the future we want to try out various colors and build up a legend basing on those colors. Dictionary is great for this:\n\ncol = 'year'\nnum_cols = 5\n\nstyle_selected = {'color': 'orange', 'lw': 2, 'zorder': 99}\nstyle_bg = {'color': 'gray', 'lw': 1, 'alpha': 0.5}\n\nnum_charts = df[col].nunique()\n\nnum_rows = (num_charts // num_cols) + 1\nremaining =  num_charts % num_cols \n\nis_xlabeled = np.zeros((num_rows, num_cols))\nis_xlabeled[-1][0:remaining] = 1\nis_xlabeled[-2][remaining:] = 1\n\nf, axes = plt.subplots(ncols=num_cols, nrows=num_rows, sharex=True, sharey=True)\ndf_pivot = df.pivot(index='m', columns=col, values='passengers')\n\nfor chosen, ax in zip_longest(df[col].unique(), axes.ravel()): \n    if chosen is not None:\n        tmp_df = df_pivot[chosen]\n        ax.plot(tmp_df, **style_selected)\n        ax.plot(df_pivot, **style_bg)\n    else: \n        ax.remove()    \n\nfor xlab, ax in zip(is_xlabeled.ravel(), axes.ravel()): \n    if xlab: \n        ax.tick_params(axis='x', which='major', labelbottom=True)\n    \n\n\n\n\nAlso, let’s not use hardcoded values for x,y values and only use df_pivot from now on.\n\ncol = 'year'\nx_col = 'm'\ny_col = 'passengers'\nnum_cols = 5\n\nstyle_selected = {'color': 'orange', 'lw': 2, 'zorder': 99}\nstyle_bg = {'color': 'gray', 'lw': 1, 'alpha': 0.5}\n\ndf_pivot = df.pivot(index=x_col, columns=col, values=y_col)\n\nnum_charts = len(df_pivot.columns)\nnum_rows = (num_charts // num_cols) + 1\nremaining =  num_charts % num_cols \n\nis_xlabeled = np.zeros((num_rows, num_cols))\nis_xlabeled[-1][0:remaining] = 1\nis_xlabeled[-2][remaining:] = 1\n\nf, axes = plt.subplots(ncols=num_cols, nrows=num_rows, sharex=True, sharey=True)\n\nfor chosen, ax in zip_longest(df_pivot.columns, axes.ravel()): \n    if chosen is not None:\n        tmp_df = df_pivot[chosen]\n        ax.plot(tmp_df, **style_selected)\n        ax.plot(df_pivot, **style_bg)\n    else: \n        ax.remove()    \n\nfor xlab, ax in zip(is_xlabeled.ravel(), axes.ravel()): \n    if xlab: \n        ax.tick_params(axis='x', which='major', labelbottom=True)\n    \n\n\n\n\nNow it looks like we have separated the data and plotting parts. We can wrap our code in a function. We define default styles inside the function, and return f and axes objects for easy modification further on.\n\ndef small_multiples(df, col, x_col, y_col, num_cols, \n                    style_selected = None, style_bg = None):\n    \n    if style_selected is None: \n        style_selected = {'color': 'orange', 'lw': 2, 'zorder': 99}\n    if style_bg is None:\n        style_bg = {'color': 'gray', 'lw': 1, 'alpha': 0.5}\n\n    df_pivot = df.pivot(index=x_col, columns=col, values=y_col)\n\n    num_charts = len(df_pivot.columns)\n    num_rows = (num_charts // num_cols) + 1\n    remaining =  num_charts % num_cols \n\n    is_xlabeled = np.zeros((num_rows, num_cols))\n    is_xlabeled[-1][0:remaining] = 1\n    is_xlabeled[-2][remaining:] = 1\n\n    f, axes = plt.subplots(ncols=num_cols, nrows=num_rows, sharex=True, sharey=True)\n\n    for chosen, ax in zip_longest(df_pivot.columns, axes.ravel()): \n        if chosen is not None:\n            tmp_df = df_pivot[chosen]\n            ax.plot(tmp_df, **style_selected)\n            ax.plot(df_pivot, **style_bg)\n        else: \n            ax.remove()    \n\n    for xlab, ax in zip(is_xlabeled.ravel(), axes.ravel()): \n        if xlab: \n            ax.tick_params(axis='x', which='major', labelbottom=True)\n\n    return f, axes\n\nWith such a structure, we can easily modify the look and feel of our small-multiples dashboard:\n\nf, axes = small_multiples(df=df, col='year', x_col='m', y_col='passengers', \n                          num_cols=5, \n                          style_selected={'color':'limegreen', 'lw':3},)\n\nf.suptitle('Flights over the years')\n\nText(0.5, 0.98, 'Flights over the years')\n\n\n\n\n\nHowever, there is something we are missing. We cannot easily scale the size of the dashboard. For this, let’s declare another variable dashboard_props, which we will pass to plt.subplots():\n\ndef small_multiples(df, col, x_col, y_col, num_cols, \n                    style_selected = None, style_bg = None, \n                    dashboard_props = None):\n    \n    if style_selected is None: \n        style_selected = {'color': 'orange', 'lw': 2, 'zorder': 99}\n    if style_bg is None:\n        style_bg = {'color': 'gray', 'lw': 1, 'alpha': 0.5}\n        \n    if dashboard_props is None:\n        dashboard_props = {}\n        \n    df_pivot = df.pivot(index=x_col, columns=col, values=y_col)\n\n    num_charts = len(df_pivot.columns)\n    num_rows = (num_charts // num_cols) + 1\n    remaining =  num_charts % num_cols \n\n    is_xlabeled = np.zeros((num_rows, num_cols))\n    is_xlabeled[-1][0:remaining] = 1\n    is_xlabeled[-2][remaining:] = 1\n\n    f, axes = plt.subplots(ncols=num_cols, nrows=num_rows, \n                           sharex=True, sharey=True, \n                           **dashboard_props)\n\n    for chosen, ax in zip_longest(df_pivot.columns, axes.ravel()): \n        if chosen is not None:\n            tmp_df = df_pivot[chosen]\n            ax.plot(tmp_df, **style_selected)\n            ax.plot(df_pivot, **style_bg)\n        else: \n            ax.remove()    \n\n    for xlab, ax in zip(is_xlabeled.ravel(), axes.ravel()): \n        if xlab: \n            ax.tick_params(axis='x', which='major', labelbottom=True)\n\n    \n    return f, axes\n\nNow we can also make x-ticks a bit more human-friendly. With the current structure, it is easy to do without having to modify the base function:\n\nf, axes = small_multiples(df=df, col='year', x_col='month', y_col='passengers', \n                          num_cols=5, \n                          style_selected={'color':'limegreen', 'lw':3},\n                         dashboard_props={'figsize': (10,5)})\n\nf.suptitle('Flights over the years')\n\nfrom matplotlib.ticker import MultipleLocator\n[ax.xaxis.set_major_locator(MultipleLocator(3)) for ax in axes.ravel()];"
  },
  {
    "objectID": "posts/mpl/mpl_small-multiples_ziplongest.html#step-5-legend-and-annotations",
    "href": "posts/mpl/mpl_small-multiples_ziplongest.html#step-5-legend-and-annotations",
    "title": "Create small-multiples charts from scratch in Matplotlib",
    "section": "Step 5: legend and annotations",
    "text": "Step 5: legend and annotations\nLet’s add annotations: at this point there is no information about the actual year!\n\ndef small_multiples(df, col, x_col, y_col, num_cols, \n                    style_selected = None, style_bg = None, \n                    dashboard_props = None, text_props = None):\n    \n    if style_selected is None: \n        style_selected = {'color': 'orange', 'lw': 2, 'zorder': 99}\n    if style_bg is None:\n        style_bg = {'color': 'gray', 'lw': 1, 'alpha': 0.5}\n        \n    if dashboard_props is None:\n        dashboard_props = {}\n        \n    default_text_props = {'x': 0.95, 'y': 0.95}\n    if text_props is None: \n        text_props = {}\n    if 'x' not in text_props.keys(): \n        text_props['x'] = default_text_props['x']\n    if 'y' not in text_props.keys(): \n        text_props['y'] = default_text_props['y']\n        \n    df_pivot = df.pivot(index=x_col, columns=col, values=y_col)\n\n    num_charts = len(df_pivot.columns)\n    num_rows = (num_charts // num_cols) + 1\n    remaining =  num_charts % num_cols \n\n    is_xlabeled = np.zeros((num_rows, num_cols))\n    is_xlabeled[-1][0:remaining] = 1\n    is_xlabeled[-2][remaining:] = 1\n\n    f, axes = plt.subplots(ncols=num_cols, nrows=num_rows, \n                           sharex=True, sharey=True, \n                           **dashboard_props)\n\n    for chosen, ax in zip_longest(df_pivot.columns, axes.ravel()): \n        if chosen is not None:\n            tmp_df = df_pivot[chosen]\n            ax.plot(tmp_df, **style_selected)\n            ax.plot(df_pivot, **style_bg)\n            ax.text(s=chosen, \n                transform=ax.transAxes, \n                va='top', ha='right', zorder=1, \n                   **text_props)\n        else: \n            ax.remove()    \n\n    for xlab, ax in zip(is_xlabeled.ravel(), axes.ravel()): \n        if xlab: \n            ax.tick_params(axis='x', which='major', labelbottom=True)\n\n    \n    return f, axes\n\n\nf, axes = small_multiples(df=df, col='year', x_col='month', y_col='passengers', \n                          num_cols=5, \n                          style_selected={'color':'limegreen', 'lw':3},\n                         dashboard_props={'figsize': (10,5)}, text_props={'size':8})\n\nf.suptitle('Flights over the years')\n\nfrom matplotlib.ticker import MultipleLocator\n[ax.xaxis.set_major_locator(MultipleLocator(3)) for ax in axes.ravel()];\n\n\n\n\nAnd let’s add a legend:\n\ndef small_multiples(df, col, x_col, y_col, num_cols, \n                    style_selected = None, style_bg = None, \n                    dashboard_props = None, text_props = None):\n    \n    if style_selected is None: \n        style_selected = {'color': 'orange', 'lw': 2, 'zorder': 99}\n    if style_bg is None:\n        style_bg = {'color': 'gray', 'lw': 1, 'alpha': 0.5}\n        \n    if dashboard_props is None:\n        dashboard_props = {}\n        \n    default_text_props = {'x': 0.95, 'y': 0.95}\n    if text_props is None: \n        text_props = {}\n    if 'x' not in text_props.keys(): \n        text_props['x'] = default_text_props['x']\n    if 'y' not in text_props.keys(): \n        text_props['y'] = default_text_props['y']\n        \n    df_pivot = df.pivot(index=x_col, columns=col, values=y_col)\n\n    num_charts = len(df_pivot.columns)\n    num_rows = (num_charts // num_cols) + 1\n    remaining =  num_charts % num_cols \n\n    is_xlabeled = np.zeros((num_rows, num_cols))\n    is_xlabeled[-1][0:remaining] = 1\n    is_xlabeled[-2][remaining:] = 1\n\n    f, axes = plt.subplots(ncols=num_cols, nrows=num_rows, \n                           sharex=True, sharey=True, \n                           **dashboard_props)\n\n    for chosen, ax in zip_longest(df_pivot.columns, axes.ravel()): \n        if chosen is not None:\n            tmp_df = df_pivot[chosen]\n            ax.plot(tmp_df, **style_selected)\n            ax.plot(df_pivot, **style_bg)\n            ax.text(s=chosen, \n                transform=ax.transAxes, \n                va='top', ha='right', zorder=1, \n                   **text_props)\n        else: \n            ax.remove()    \n\n    for xlab, ax in zip(is_xlabeled.ravel(), axes.ravel()): \n        if xlab: \n            ax.tick_params(axis='x', which='major', labelbottom=True)\n    \n    from matplotlib.lines import Line2D\n    labels = ['selected year', 'other years']\n    handles = [Line2D([0], [0], **style_selected), Line2D([0], [0], **style_bg)]\n    \n    axes.ravel()[num_charts-1]\\\n        .legend(labels=labels, handles=handles,\n              bbox_to_anchor=[1.25,0.5], loc='center left', \n              edgecolor='white', facecolor='white',\n              borderpad=0, borderaxespad=0)\n    \n    return f, axes\n\n\nf, axes = small_multiples(df=df, col='year', x_col='month', y_col='passengers', \n                          num_cols=5, \n                          style_selected={'color':'limegreen', 'lw':3},\n                         dashboard_props={'figsize': (10,5)}, text_props={'size':8})\n\nf.suptitle('Flights over the years')\n\nfrom matplotlib.ticker import MultipleLocator\n[ax.xaxis.set_major_locator(MultipleLocator(3)) for ax in axes.ravel()];"
  },
  {
    "objectID": "posts/mpl/tick_formatting.html",
    "href": "posts/mpl/tick_formatting.html",
    "title": "Tick formatting recipes",
    "section": "",
    "text": "mpl gallery about ticks\nmpl ticker API"
  },
  {
    "objectID": "posts/mpl/tick_formatting.html#default-tick-formatter",
    "href": "posts/mpl/tick_formatting.html#default-tick-formatter",
    "title": "Tick formatting recipes",
    "section": "Default tick formatter",
    "text": "Default tick formatter\nfrom matplotlib.ticker import ScalarFormatter\nax.xaxis.set_major_formatter(ScalarFormatter())"
  },
  {
    "objectID": "posts/mpl/tick_formatting.html#format-string-as-usually",
    "href": "posts/mpl/tick_formatting.html#format-string-as-usually",
    "title": "Tick formatting recipes",
    "section": "Format string as usually",
    "text": "Format string as usually\nfrom matplotlib.ticker import StrMethodFormatter\nax.xaxis.set_major_formatter(StrMethodFormatter('{x:.1f}'))"
  },
  {
    "objectID": "posts/mpl/tick_formatting.html#ticks-in-a-scientificengineering-notation",
    "href": "posts/mpl/tick_formatting.html#ticks-in-a-scientificengineering-notation",
    "title": "Tick formatting recipes",
    "section": "Ticks in a scientific/engineering notation",
    "text": "Ticks in a scientific/engineering notation\nfrom matplotlib.ticker import EngFormatter\nax.xaxis.set_major_formatter(EngFormatter(sep='')) # no unit, no distance to the multiplier \nax.xaxis.set_major_formatter(EngFormatter(unit='Hz')) \nsrc"
  },
  {
    "objectID": "posts/mpl/tick_formatting.html#percent-formatter-that-does-the-scaling-too",
    "href": "posts/mpl/tick_formatting.html#percent-formatter-that-does-the-scaling-too",
    "title": "Tick formatting recipes",
    "section": "Percent formatter that does the scaling too",
    "text": "Percent formatter that does the scaling too\nfrom matplotlib.ticker import PercentFormatter\nvalue_100perc = 2.5 # data value corresponding to the 100%\nax.xaxis.set_major_formatter(PercentFormatter(xmax=value_100perc))"
  },
  {
    "objectID": "posts/mpl/tick_formatting.html#lambda-formatter-func-formatter",
    "href": "posts/mpl/tick_formatting.html#lambda-formatter-func-formatter",
    "title": "Tick formatting recipes",
    "section": "Lambda formatter (func formatter)",
    "text": "Lambda formatter (func formatter)\nOption 1:\nfrom matplotlib import ticker \n\n@ticker.FuncFormatter\ndef custom_formatter(x, pos):\n    return f'[{x:.2f}]'\n\nax.xaxis.set_major_formatter(custom_formatter)\nOption 2:\nfrom matplotlib.ticker import FuncFormatter \n\ncustom_formatter = lambda x, pos: f'[{x:.2f}]'\nax.xaxis.set_major_formatter(FuncFormatter(custom_formatter))\nsrc"
  },
  {
    "objectID": "posts/mpl/tick_formatting.html#space-as-a-separator-between-thousands",
    "href": "posts/mpl/tick_formatting.html#space-as-a-separator-between-thousands",
    "title": "Tick formatting recipes",
    "section": "Space as a separator between thousands",
    "text": "Space as a separator between thousands\n\nimport matplotlib.pyplot as plt \n\ny = [0, 1e4, 2.3e4, 3.12e4]\nx = [2000, 2010, 2020, 2030]\n\nUse the FuncFormatter, which requires a function of a form:\ndef my_func(x,pos): \n    # blablabla \n    return formatted_x_string\nNow implement the formatter. We want every 3 digits separated by a space, and our labels to be integers (won’t work for floats). We will use format(), which accepts parameter ,d producing comma-separated notation, and replace the commas with spaces.\nThe formatter can be applied to each axis separately.\nfrom matplotlib.ticker import FuncFormatter\nformat_spaces = lambda x, pos: format(int(round(x)), ',d').replace(',',' ')\nax.yaxis.set_major_formatter(FuncFormatter(format_spaces))\n\nf, ax = plt.subplots()\nax.plot(x,y,marker='o')\n\nfrom matplotlib.ticker import FuncFormatter\nformat_spaces = lambda x, pos: format(int(round(x)), ',d').replace(',',' ')\nax.yaxis.set_major_formatter(FuncFormatter(format_spaces))"
  },
  {
    "objectID": "posts/mpl/various_resources.html",
    "href": "posts/mpl/various_resources.html",
    "title": "Various Matplotlib resources",
    "section": "",
    "text": "Tueplots\n\nsets of rcParams as dictionaries adapted to various styling requirements\nconfiguration for ML conferences: AISTATS 2022, method-of-machine-learning group in Tübingen, ICML 2022, JMLR 2001, Neurips 2021, Neurips 2022\n\nSciencePlots\n\nScience, IEEE\ncolor and line style cyclers for academic publishing\n\nMetBrewer\n\ncollection of color palettes inspired by the works of art from Met Gallery\ninstall via pip install git+https://github.com/BlakeRMills/MetBrewer.git#subdirectory=Python src\nnot all the pallettes from R are ported into Python"
  },
  {
    "objectID": "posts/mpl/various_resources.html#stylesheets-rcparams-cyclers-color-palettes",
    "href": "posts/mpl/various_resources.html#stylesheets-rcparams-cyclers-color-palettes",
    "title": "Various Matplotlib resources",
    "section": "",
    "text": "Tueplots\n\nsets of rcParams as dictionaries adapted to various styling requirements\nconfiguration for ML conferences: AISTATS 2022, method-of-machine-learning group in Tübingen, ICML 2022, JMLR 2001, Neurips 2021, Neurips 2022\n\nSciencePlots\n\nScience, IEEE\ncolor and line style cyclers for academic publishing\n\nMetBrewer\n\ncollection of color palettes inspired by the works of art from Met Gallery\ninstall via pip install git+https://github.com/BlakeRMills/MetBrewer.git#subdirectory=Python src\nnot all the pallettes from R are ported into Python"
  },
  {
    "objectID": "posts/mpl/various_resources.html#matplotlib-extensions",
    "href": "posts/mpl/various_resources.html#matplotlib-extensions",
    "title": "Various Matplotlib resources",
    "section": "Matplotlib extensions",
    "text": "Matplotlib extensions\n\nCookiecutter repository for new extensions\nOfficial list of 3rd party packages"
  },
  {
    "objectID": "posts/mpl/various_resources.html#helper-modules",
    "href": "posts/mpl/various_resources.html#helper-modules",
    "title": "Various Matplotlib resources",
    "section": "Helper modules",
    "text": "Helper modules\n\ncolour\n\nsimple way to manipulate color representations"
  },
  {
    "objectID": "posts/mpl/watermarks_footnotes.html",
    "href": "posts/mpl/watermarks_footnotes.html",
    "title": "Watermarks, footnotes and other annotations",
    "section": "",
    "text": "import matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/mpl/watermarks_footnotes.html#add-a-watermark",
    "href": "posts/mpl/watermarks_footnotes.html#add-a-watermark",
    "title": "Watermarks, footnotes and other annotations",
    "section": "Add a watermark",
    "text": "Add a watermark\nSometimes you want a big fat text on your chart that says that these are preliminary results.\n\nf, ax = plt.subplots()\n\nimport matplotlib.patheffects as path_effects\n\nwatermark_text = 'draft'\nt = ax.text(0.5, 0.5, watermark_text, transform=ax.transAxes,\n        fontsize=80, color='white', alpha=0.3,  weight=\"bold\", \n        ha='center', va='center', rotation='30')\nt.set_path_effects([path_effects.Stroke(linewidth=3, foreground='lightgray')])\n\n\n\n\nChange color='white' to make it colorful. The edge color is encoded in set_path_effects as foreground."
  },
  {
    "objectID": "posts/mpl/watermarks_footnotes.html#add-a-footnote",
    "href": "posts/mpl/watermarks_footnotes.html#add-a-footnote",
    "title": "Watermarks, footnotes and other annotations",
    "section": "Add a footnote",
    "text": "Add a footnote\n\nBottom right\n\nf, ax = plt.subplots()\n\nfootnote = [\n    'Data source: XY',\n    'Author: TK'\n]\n\nax.annotate('\\n'.join(footnote), \n            xy = (1.05,0), xycoords=ax, ha='left', va='bottom',\n            fontsize=8, style='italic', \n            bbox=dict(boxstyle='square,pad=0.0',fc='none', ec='none')\n        )\n\nText(1.05, 0, 'Data source: XY\\nAuthor: TK')\n\n\n\n\n\nThe footnote is positioned relative to the axes (xycoords+ha+va). The pad is removed. Aligning to bottom makes it robust for multiline entries.\n\n\nBottom left under the chart\n\nf, ax = plt.subplots()\n\nfootnote = [\n    'Data source: XY',\n    'Author: TK'\n]\n\nax.annotate('|'.join(footnote), \n            xy = (0,-0.25), xycoords=ax, ha='left', va='top',\n            fontsize=8, style='italic', \n            bbox=dict(boxstyle='square,pad=0.0',fc='none', ec='none')\n        )\n\nText(0, -0.25, 'Data source: XY|Author: TK')\n\n\n\n\n\n\nf, ax = plt.subplots()\n\nfootnote = [\n    'Data source: XY',\n    'Author: TK'\n]\n\nax.annotate(footnote[0], \n            xy = (0,-0.25), xycoords=ax, ha='left', va='top',\n            fontsize=8, style='italic', \n            bbox=dict(boxstyle='square,pad=0.0',fc='none', ec='none')\n        )\nax.annotate(footnote[1], \n            xy = (1,-0.25), xycoords=ax, ha='right', va='top',\n            fontsize=8, style='italic', \n            bbox=dict(boxstyle='square,pad=0.0',fc='none', ec='none')\n        )\n\nText(1, -0.25, 'Author: TK')"
  },
  {
    "objectID": "posts/other_tech/conda_environments.html",
    "href": "posts/other_tech/conda_environments.html",
    "title": "Doing things with conda environments",
    "section": "",
    "text": "Update the Python version\nIt’s scary, but needs to be done sometimes (e.g. when you have a perfectly working old environment built on Python 3.6, but then one dependency stops behaving and requires P3.8+).\nIf in a conda environment:\nconda activate my_env\nconda install -c anaconda python=&lt;version&gt;\nsrc\n\n\nClone an environment\nIf you want to make a clone of the environment for a backup purpose:\nconda create --name &lt;target_environment&gt; --clone &lt;source_environment&gt; \nIf you want to clone the base:\nconda create --name &lt;myenv&gt; --clone base\n\n\nSolve the libarchive error\nhttps://github.com/ContinuumIO/anaconda-issues/issues/11104#issuecomment-510285329\n\ninstall miniconda to a separate folder. Tell it not to run conda init\nactivate that installation with source /path/to/new/miniconda/bin/activate\nrun conda install -p /path/to/broken/anaconda –force python-libarchive-c conda-package-handling libarchive\n\nSimilar here: https://github.com/conda/conda/issues/7714#issuecomment-417553149\n\n\nInstall packages when creating environment\nPackages can be defined at env creation, which supposedly helps with resolving conflicts\n\n\nBasics\nList environments:\nconda info --envs \nInstall ipykernel pointing to a venv:\npip install ipykernel \npython -m ipykernel install --name my_venv"
  },
  {
    "objectID": "posts/other_tech/ejs.html",
    "href": "posts/other_tech/ejs.html",
    "title": "Writing EJS templates",
    "section": "",
    "text": "When writing custom templates, categories are joined into string which is comma-separated but has no spaces between the categories. Because of that, if the text is wider than its container, it will overflow instead of being wrapped. One solution is to add spaces using String.replace():\n&lt;%= String(item.categories).replace(/,/g, ', ') %&gt;"
  },
  {
    "objectID": "posts/other_tech/poetry.html",
    "href": "posts/other_tech/poetry.html",
    "title": "Poetry tips and tricks",
    "section": "",
    "text": "Install ipykernel as development dependency:\npoetry add -D ipykernel\nRegister the ipykernel:\npoetry run python -m ipykernel install --user --name my_kernel\nCheck that the kernel is registered:\njupyter kernelspec list"
  },
  {
    "objectID": "posts/other_tech/poetry.html#mount-an-ipykernel-in-a-poetry-environment-to-use-with-your-global-jupyter",
    "href": "posts/other_tech/poetry.html#mount-an-ipykernel-in-a-poetry-environment-to-use-with-your-global-jupyter",
    "title": "Poetry tips and tricks",
    "section": "",
    "text": "Install ipykernel as development dependency:\npoetry add -D ipykernel\nRegister the ipykernel:\npoetry run python -m ipykernel install --user --name my_kernel\nCheck that the kernel is registered:\njupyter kernelspec list"
  },
  {
    "objectID": "posts/other_tech/poetry.html#install-the-main-package-in-the-ipykernel-so-that-its-available-from-anywhere",
    "href": "posts/other_tech/poetry.html#install-the-main-package-in-the-ipykernel-so-that-its-available-from-anywhere",
    "title": "Poetry tips and tricks",
    "section": "Install the main package in the ipykernel so that it’s available from anywhere",
    "text": "Install the main package in the ipykernel so that it’s available from anywhere\nPoetry by default will try to do it, but Jupyter will not recognize this. You need to add a setup.py alongside your __init__.py:\nfrom setuptools import setup, find_packages\n\nsetup(\n    name='name_of_your_package',\n    version='0.1.0',\n    packages=find_packages(include=['name_of_your_package', 'name_of_your_package.*'])\n)"
  },
  {
    "objectID": "posts/other_tech/poetry.html#see-the-location-of-the-current-venv",
    "href": "posts/other_tech/poetry.html#see-the-location-of-the-current-venv",
    "title": "Poetry tips and tricks",
    "section": "See the location of the current venv:",
    "text": "See the location of the current venv:\npoetry env info --path"
  },
  {
    "objectID": "posts/other_tech/poetry.html#managing-different-poetry-environments-in-different-branches",
    "href": "posts/other_tech/poetry.html#managing-different-poetry-environments-in-different-branches",
    "title": "Poetry tips and tricks",
    "section": "Managing different poetry environments in different branches",
    "text": "Managing different poetry environments in different branches\nBy default, Poetry will create one global environment for a given project name. This can be problematic when you use different dependencies on different branches, but within the same project.\n\nSolution 1: recreate the environment at switch\nSwitch branches and recreate the environment from scratch:\npoetry env list\npoetry env remove env_name_like_listed_above\npoetry lock\npoetry install \nor\npoetry install --remove-untracked\n\n\nSolution 2: keep branches in separate directories and make poetry create local environments\nClone each branch into a separate local directory. To make poetry create separate environments w/o having to rename the project name in pyproject.toml, run:\n\nfor all the projects:\n\npoetry config virtualenvs.in-project true\n\nonly for those projects - run separately in each directory\n\npoetry config virtualenvs.in-project true --local\nAnd then run:\npoetry lock \npoetry install\nLock is important to create a new venv.\nTo see the current config:\npoetry config --list\nsrc1 src2 src3\nThen mount Ipython kernel in each environment separately."
  },
  {
    "objectID": "posts/other_tech/table_like_li_css.html",
    "href": "posts/other_tech/table_like_li_css.html",
    "title": "Style a list element to look like a table",
    "section": "",
    "text": "The HTML part\n&lt;div class=\"custom_listing\"&gt;\n&lt;ul&gt;\n&lt;li&gt;\n    &lt;span class=\"li-contents-container\"&gt;\n        &lt;span class=\"left-container\"&gt;\n            Here the left part of the list element. Can consist of spans.\n        &lt;/span&gt;\n        &lt;span class=\"right-container\"&gt;\n            Something that will be aligned to the right.\n        &lt;/span&gt;\n    &lt;/span&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;\n\n\nThe CSS part\n.custom_listing li .li-contents-container{\n    display: flex; \n    align-items: center;\n}\n\n.custom_listing .left-container {\n    width: 70%;\n    margin-right: auto;\n}\n\n.custom_listing .right-container {\n    max-width: 25%;\n    margin-left: auto; \n    text-align: right;\n}\n\n\nRemark\nHaving a parent li-contents-container is crucial to be able to display a bullet point or another symbol for each &lt;li&gt; item.\nsrc"
  },
  {
    "objectID": "posts/other_tech/useful_git.html",
    "href": "posts/other_tech/useful_git.html",
    "title": "Useful git stuff",
    "section": "",
    "text": "Because every now and then there is this thing you need to do with git, but because you do it not so often, you have to google it for like 30 sec."
  },
  {
    "objectID": "posts/other_tech/useful_git.html#branches",
    "href": "posts/other_tech/useful_git.html#branches",
    "title": "Useful git stuff",
    "section": "Branches",
    "text": "Branches\nTo create a new completely empty branch:\ngit switch --orphan &lt;new branch&gt;\ngit commit --allow-empty -m \"Initial commit on orphan branch\"\ngit push -u origin &lt;new branch&gt;\nsrc Article on branches\nTo pull a new branch from the server without touching the current branch: git fetch &lt;remote_name&gt; &lt;branch_name&gt; which in most cases is src\ngit fetch origin &lt;branch_name&gt;"
  },
  {
    "objectID": "posts/other_tech/useful_git.html#unstaging-files",
    "href": "posts/other_tech/useful_git.html#unstaging-files",
    "title": "Useful git stuff",
    "section": "Unstaging files",
    "text": "Unstaging files\nhttps://sethrobertson.github.io/GitFixUm/fixup.html\n\nadded but not committed\n\n\ncommitted but not pushed\nhttps://stackoverflow.com/a/15321456\ngit reset --soft HEAD^ \ngit reset HEAD path/to/unwanted_file\ngit commit -c ORIG_HEAD \nThe last command will recommit with the original commit message"
  },
  {
    "objectID": "posts/pandas/generate_fake_dates_in_pandas.html",
    "href": "posts/pandas/generate_fake_dates_in_pandas.html",
    "title": "Generating random days between two dates",
    "section": "",
    "text": "import pandas as pd \nimport numpy as np\nstart_date = '2010-03-23'\nend_date = '2013-07-19'"
  },
  {
    "objectID": "posts/pandas/generate_fake_dates_in_pandas.html#generate-all-days-between-two-dates",
    "href": "posts/pandas/generate_fake_dates_in_pandas.html#generate-all-days-between-two-dates",
    "title": "Generating random days between two dates",
    "section": "Generate all days between two dates:",
    "text": "Generate all days between two dates:\n\npd.date_range(start_date, end_date, freq='D')\n\nDatetimeIndex(['2010-03-23', '2010-03-24', '2010-03-25', '2010-03-26',\n               '2010-03-27', '2010-03-28', '2010-03-29', '2010-03-30',\n               '2010-03-31', '2010-04-01',\n               ...\n               '2013-07-10', '2013-07-11', '2013-07-12', '2013-07-13',\n               '2013-07-14', '2013-07-15', '2013-07-16', '2013-07-17',\n               '2013-07-18', '2013-07-19'],\n              dtype='datetime64[ns]', length=1215, freq='D')"
  },
  {
    "objectID": "posts/pandas/generate_fake_dates_in_pandas.html#generate-n-dates-equally-spaced",
    "href": "posts/pandas/generate_fake_dates_in_pandas.html#generate-n-dates-equally-spaced",
    "title": "Generating random days between two dates",
    "section": "Generate N dates equally spaced:",
    "text": "Generate N dates equally spaced:\n\nN = 4\n\npd.date_range(start_date, end_date, periods=N).normalize()\n\nDatetimeIndex(['2010-03-23', '2011-05-01', '2012-06-09', '2013-07-19'], dtype='datetime64[ns]', freq=None)"
  },
  {
    "objectID": "posts/pandas/generate_fake_dates_in_pandas.html#generate-a-random-subsample-of-n-dates-between-the-dates",
    "href": "posts/pandas/generate_fake_dates_in_pandas.html#generate-a-random-subsample-of-n-dates-between-the-dates",
    "title": "Generating random days between two dates",
    "section": "Generate a random subsample of N dates between the dates",
    "text": "Generate a random subsample of N dates between the dates\nMethod 1 & 2 require to generate the whole date range first, then sample from it. Method 3 & 4 leverage numpy generators and construct dates out of generated numbers. Method 2 doesn’t require explicitly importing numpy. Method 4 gives you the times for free as well and seems the fastest according to the benchmark in the original SO thread\n\nMethod 1:\nnp.random.choice src\n\n# old syntax\n\nN = 4\n\npd.Series(\n    np.random.choice(\n        pd.date_range(start_date, end_date), \n        N, \n        replace=True # replace=True -&gt; 1 value can appear multiple times\n    )\n) \n\n0   2010-12-07\n1   2010-05-20\n2   2011-12-17\n3   2013-02-24\ndtype: datetime64[ns]\n\n\n\n# new syntax\n\nrng = np.random.default_rng()\n\nN = 4\n\npd.Series(\n    rng.choice(\n        pd.date_range(start_date, end_date), \n        N, \n        replace=True # replace=True -&gt; 1 value can appear multiple times\n    )\n) \n\n0   2013-03-16\n1   2010-11-18\n2   2012-05-27\n3   2011-03-24\ndtype: datetime64[ns]\n\n\n\n\nMethod 2:\npd.Series.sample()\n\nN = 4\n\npd.Series(\n    pd.date_range(start_date, end_date, freq='D')\n)\\\n.sample(N, replace=True)\\\n.reset_index(drop=True)\n\n0   2012-05-05\n1   2012-10-20\n2   2013-02-04\n3   2011-01-03\ndtype: datetime64[ns]\n\n\n\n\nMethod 3:\npd.to_timedelta\n\n# old syntax\n\nN = 4\n\nmax_days = (pd.to_datetime(end_date) - pd.to_datetime(start_date)).days\ndelta_days = pd.to_timedelta(\n    np.random.randint(0, max_days+1, N), \n    unit='D')\n\npd.to_datetime(start_date) + delta_days\n\nDatetimeIndex(['2013-05-10', '2011-07-19', '2011-05-14', '2013-01-30'], dtype='datetime64[ns]', freq=None)\n\n\n\n# new syntax\n\nrng = np.random.default_rng()\n\nN = 4\n\nmax_days = (pd.to_datetime(end_date) - pd.to_datetime(start_date)).days\ndelta_days = pd.to_timedelta(\n    rng.integers(0, max_days, size=N, endpoint=True), \n    unit='D')\n\npd.to_datetime(start_date) + delta_days\n\nDatetimeIndex(['2013-02-17', '2012-02-21', '2011-04-13', '2013-02-20'], dtype='datetime64[ns]', freq=None)\n\n\n\n\nMethod 4:\nunix timestamps src\n\n# old syntax\n\nN = 4\n\nstart_u = pd.to_datetime(start_date).value//int(1e9)\nend_u = pd.to_datetime(end_date).value//int(1e9)\npd.to_datetime(np.random.randint(start_u, end_u, N), unit='s').normalize()\n\nDatetimeIndex(['2010-07-15', '2011-05-11', '2010-10-30', '2010-05-19'], dtype='datetime64[ns]', freq=None)\n\n\n\n# new syntax\n\nrng = np.random.default_rng()\n\nN = 4\n\nstart_u = pd.to_datetime(start_date).value//int(1e9)\nend_u = pd.to_datetime(end_date).value//int(1e9)\npd.to_datetime(rng.integers(start_u, end_u, N, endpoint=True), unit='s').normalize()\n\nDatetimeIndex(['2011-03-22', '2011-08-23', '2012-12-26', '2010-08-05'], dtype='datetime64[ns]', freq=None)"
  },
  {
    "objectID": "posts/pandas/installing_geopandas.html",
    "href": "posts/pandas/installing_geopandas.html",
    "title": "Installing geopandas on Windows",
    "section": "",
    "text": "The first time I tried to make geopandas work on Windows, I spent 2 days struggling. The official way to install it using conda never worked for me. Finally I found a way, but I was terrified of having to do it again, so I tried to keep and reuse this virtual environment as long as I can. Unfortunately, some time ago I had to nuke my whole Anaconda installation in order to upgrade the base Python and lost the environment. Luckily, I found this excellent tutorial by Francis Adrian Viernes that helped me set up a geopandas environment in no time!\nHere are the steps, how they worked for me:\nThis recipe worked for Windows 10 Professional, Python 3.9.12, conda 4.12.0, pip 22.3, GDAL 3.4.3, PyProj 3.3.1, Fiona 1.8.21, Shapely 1.8.2, geopandas 0.12.1."
  },
  {
    "objectID": "posts/pandas/installing_geopandas.html#footnotes",
    "href": "posts/pandas/installing_geopandas.html#footnotes",
    "title": "Installing geopandas on Windows",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote: Gohlke’s wheels used to be hosted on his University of California, Irvine webpage. This page is no longer functional.↩︎"
  },
  {
    "objectID": "posts/pandas/pandas_dictionaries.html",
    "href": "posts/pandas/pandas_dictionaries.html",
    "title": "Generate dictionaries from dataframes",
    "section": "",
    "text": "Sometimes it is useful to use dictionaries in pandas workflows. For example, when using a df.replace() or df.rename() command. Sometimes it is useful when those dictionaries are generated from another dataframe.\nConcrete example could be working with messy country names. Let’s say I have a dataframe containing some values per country:\ndf = pd.DataFrame([['Poland', 'Jan Nowak', 3], ['POL', 'Martyna Kowalska', 15], ['PL', 'Joanna Byk', 19]], \n        columns=['country', 'athlete', 'score'])\nand another dataframe which contains attribution of a messy country name to a proper country name:\ncountries = pd.DataFrame(['Poland', 'PL'], ['POL', 'PL'], ['PL', 'PL'], columns=['messy', 'proper'])\nHere countries is generated programmatically, but the benefit of using a countries dataframe is that it can be maintained in a form of an external csv or xlsx, which contains a hand-curated list of synonyms.\nWhat we want to get is a dictionary of a form: {'messy_name': 'proper_name'}.\nWe can achieve it in a following way:\nnames_dict = countries.drop_duplicates().set_index('messy')['proper'].to_dict()\nWe need to drop duplicates, otherwise we will only get the first entry (keys are unique in a dictionary). Optimally we would do it at the earlier stage.\nTo clean the messy names, we can then do:\ndf['country'].replace(names_dict)\nto get a disambiguated column. We can overwrite the original or create a new column, e.g. country_clean."
  },
  {
    "objectID": "posts/pandas/reading_messy_csvs.html",
    "href": "posts/pandas/reading_messy_csvs.html",
    "title": "Dealing with messy CSVs",
    "section": "",
    "text": "In the wild, some data come as messy CSVs or TXT files. Luckily, we can customize the pd.read_csv() to deal with many surprises that await us."
  },
  {
    "objectID": "posts/pandas/reading_messy_csvs.html#configure-the-file-imports",
    "href": "posts/pandas/reading_messy_csvs.html#configure-the-file-imports",
    "title": "Dealing with messy CSVs",
    "section": "Configure the file imports",
    "text": "Configure the file imports\nTo set the explicit file encoding, for a case when the non-Latin characters were saved in a weird way. Pick your favorite one (ansi, utf-8 etc.)\npd.read_csv('messyfile.txt', encoding='ansi')\nDelimiter other than a comma. Common delimiters are: \\t for tab, | for pipe etc.\npd.read_csv('messyfile.tsv', delimiter='\\t')\npd.read_csv('messyfile.tsv', sep='\\t')\nYour CSV has a commentary on top of your data and you know how many lines there are (here, 9 lines of commentary):\npd.read_csv('messyfile.csv', skiprows=9)\nYour CSV has a commentary above/in/below your data and it is preceded with a #:\npd.read_csv('messyfile.csv', comment='#')\nYour CSV has data which look like NaN, but are actually proper data points, e.g. a shortcut NA for North America: (this will also switch off all the other ways of fishing out the NaN values)\npd.read_csv('messyfile.csv', na_filter=False)\nYour CSV has textual data which contain a valid double-quote character as part of the string which has been escaped with \\:\npd.read_csv('messyfile.csv', escapechar='\\')\nYou know that the table is at the beginning of the file and it takes 11 lines, and below the table there is an unknown volume of garbage/commentary:\npd.read_csv('messyfile.csv', nrows=11)"
  },
  {
    "objectID": "posts/pandas/reading_messy_csvs.html#how-to-snoop-the-file-before-reading",
    "href": "posts/pandas/reading_messy_csvs.html#how-to-snoop-the-file-before-reading",
    "title": "Dealing with messy CSVs",
    "section": "How to snoop the file before reading",
    "text": "How to snoop the file before reading\nSometimes the mess is big and we want to snoop the file first and decide between an import scenario.\nFor example, we have a set of csvs and the headers are missing in some of them. The columns should be the same in each file. We know what the default header should be. We can store it in a variable:\nheaderline = 'col1,col2,col3'\nheader_names = headerline.split(',')\nIf your column names are messy, you may want to strip them from whitespace etc. in this step.\nThen we can open each csv file separately, snoop the beginning and decide on the import scenario. It is important to move back the cursor to the beginning after performing a read operation.\nwith open('single_file.csv') as tmp_file:\n\n  # snoop the first line and move the file pointer back to the file beginning \n  x = tmp_file.tell() # get the initial position \n  first_line = tmp_file.readline().decode('utf-8') # snoop \n  tmp_file.seek(x) # move the pointer back to the iniital position \n  \n  # do something depending on what we found out \n  if first_line != headerline: # if the headerline is missing at the beginning \n      df_tmp = pd.read_csv(tmp_file, delimiter=',', \n                            header=0, names=header_names) # read header manually\n      # here you can do something else to your data to clean it\n  else: \n      df_tmp = pd.read_csv(tmp_file, delimiter=',') # read as usual \nI had a real case like this, where in the bunch of CSVs the header was sometimes above and sometimes below the data table. I want to believe that a person who created this data set must have had a very very bad day."
  },
  {
    "objectID": "posts/pandas/reading_messy_csvs.html#to-merge-the-csvs-into-one-big-dataframe",
    "href": "posts/pandas/reading_messy_csvs.html#to-merge-the-csvs-into-one-big-dataframe",
    "title": "Dealing with messy CSVs",
    "section": "To merge the csvs into one big dataframe",
    "text": "To merge the csvs into one big dataframe\nThe best is to use pd.concat():\ndf_list = []\nfor f in list_of_files: \n  df_tmp = pd.read_csv(f) # here you can use your customized read function like in the snooping example\n  df_list.append(df_tmp)\nbig_df = pd.concat(df_list).reset_index()\nRemember to reset_index(), as all the dataframes will come with their own index, which may screw up your loc operations later on if you leave duplicate indices."
  },
  {
    "objectID": "posts/pandas/skipping_arbitrary_empty_rows.html",
    "href": "posts/pandas/skipping_arbitrary_empty_rows.html",
    "title": "Skipping empty csv rows",
    "section": "",
    "text": "Let’s say you got a series of csv files which contain tabular data, but there is a certain amount of commentary above the table:\nComment line 1 \nComment line 2 \nComment line 3 \n\ncol1, col2, col3 \n10, 12, 13\n21, 20, 22\nPandas accepts also file objects as an input, so you can travel through the lines until you find a separating line (or another condition) and then proceed with pd.read_csv:\nimport pandas as pd\n\nf = open(\"data.csv\")\nwhile f.readline() != '\\n':\n    pass\n\ndf = pd.read_csv(f, header=None)\nf.close()\nAs suggested in src"
  },
  {
    "objectID": "posts/pandas/various_pandas_resources.html",
    "href": "posts/pandas/various_pandas_resources.html",
    "title": "Various Pandas resources",
    "section": "",
    "text": "Data manipulation R-Python conversion guide\nRPY2 github and docs"
  },
  {
    "objectID": "posts/pandas/various_pandas_resources.html#r-related",
    "href": "posts/pandas/various_pandas_resources.html#r-related",
    "title": "Various Pandas resources",
    "section": "",
    "text": "Data manipulation R-Python conversion guide\nRPY2 github and docs"
  },
  {
    "objectID": "posts/pandas/weekday_weekname.html",
    "href": "posts/pandas/weekday_weekname.html",
    "title": "Weekday names in pandas",
    "section": "",
    "text": "Pandas offers you a functionality to read the day of the week out of a datetime column: dt.weekday. However these are values ranging from 0..6. Is there a better way to convert them to human-readable days rather than using our real-world knowledge? (yes, there is!)\n\nimport pandas as pd \n\n\ngenerate the weekday names in a given locale\nWe can use the .dt.day_name() function to generate named days. This function alone gets us only to discover that 2018-01-01 was a Monday. But we can do the following:\n\nGenerate 7 consecutive dates with pd.date_range()\nFor each of them, read out its .dt.weekday\nFor each of them, read out its .dt.day_name()\nIgnore/drop the first column and use the dataframe as a mapping between the integer denoting a day and its human-readable form.\n\nBonus: we can generate named days in a given locale. So for example to obtain a mapping between integers, day names in English, day names in German:\n\ns = pd.DataFrame(pd.date_range(start='2018-01-01', freq='D', periods=7), columns=['date'])\ns['weekday'] = s['date'].dt.weekday\ns['weekday_en'] = s['date'].dt.day_name()\ns['weekday_de'] = s['date'].dt.day_name(locale='de')\ns \n\n\n\n\n\n\n\n\ndate\nweekday\nweekday_en\nweekday_de\n\n\n\n\n0\n2018-01-01\n0\nMonday\nMontag\n\n\n1\n2018-01-02\n1\nTuesday\nDienstag\n\n\n2\n2018-01-03\n2\nWednesday\nMittwoch\n\n\n3\n2018-01-04\n3\nThursday\nDonnerstag\n\n\n4\n2018-01-05\n4\nFriday\nFreitag\n\n\n5\n2018-01-06\n5\nSaturday\nSamstag\n\n\n6\n2018-01-07\n6\nSunday\nSonntag\n\n\n\n\n\n\n\nWe can add variations of weekday names, such as:\n\ns['weekday_short'] = s['weekday_en'].apply(lambda x: x[0:3]).str.upper()\n\nWe can also create a dictionary:\n\nweekday_dict = s[['weekday', 'weekday_short']].set_index('weekday_short')['weekday'].to_dict()\nweekday_dict\n\n{'MON': 0, 'TUE': 1, 'WED': 2, 'THU': 3, 'FRI': 4, 'SAT': 5, 'SUN': 6}"
  },
  {
    "objectID": "posts/pandas/working_with_datetimes.html",
    "href": "posts/pandas/working_with_datetimes.html",
    "title": "Working with datetimes",
    "section": "",
    "text": "Working with datetimes\n\nimport pandas as pd\n\n\nTo extract just date from a full datetime\n\ns = pd.Series(pd.date_range(\"20130101\", periods=4, freq='H'))\ns\n\n0   2013-01-01 00:00:00\n1   2013-01-01 01:00:00\n2   2013-01-01 02:00:00\n3   2013-01-01 03:00:00\ndtype: datetime64[ns]\n\n\nKeep just the date:\n\ns.dt.date\n\n0    2013-01-01\n1    2013-01-01\n2    2013-01-01\n3    2013-01-01\ndtype: object\n\n\nKeep just the date as datetime object:\n\ns.dt.date.astype('datetime64')\n\n0   2013-01-01\n1   2013-01-01\n2   2013-01-01\n3   2013-01-01\ndtype: datetime64[ns]\n\n\nKeep just the date by resetting the timestamp:\n\ns.dt.normalize()\n\n0   2013-01-01\n1   2013-01-01\n2   2013-01-01\n3   2013-01-01\ndtype: datetime64[ns]\n\n\nKeep the date with a particular formatting:\n\ns.dt.strftime(\"%Y/%m/%d\")\n\n0    2013/01/01\n1    2013/01/01\n2    2013/01/01\n3    2013/01/01\ndtype: object\n\n\nLinks:\n- source\n- .dt docs"
  },
  {
    "objectID": "posts/tips_quarto/ojs_define_series.html",
    "href": "posts/tips_quarto/ojs_define_series.html",
    "title": "Coupling Python and Observable using ojs_define()",
    "section": "",
    "text": "See src and this Issue\n\nimport pandas as pd \nmy_variable = pd.Series([0,1,2,3])\nojs_define(my_variable = pd.DataFrame(my_variable)) # this works\nojs_define(my_variable2 = my_variable.tolist()) # this works\n# ojs_define(my_variable = my_variable) # this doesn't\n\n\n\n\n\n\n\n\nmy_variable"
  },
  {
    "objectID": "posts/tips_quarto/quarto_howto.html",
    "href": "posts/tips_quarto/quarto_howto.html",
    "title": "Quarto how-to",
    "section": "",
    "text": "src\n\nCreate a template with an .ejs extension\nitems stores your list items. You can loop through them. Every item has parameters corresponding to the listing fields, e.g. item.title, item.date etc. You need to wrap them in special brackets, e.g. &lt;%= item.title %&gt;\nYou can define divs, spans and other elements, and add classes to them. Then you can modify the styling using css, e.g. in your main styles.css file or another file\nTo use the template, in the listing part of the document, instead of type: default declare template: path\\to\\custom_listing_declaration.ejs"
  },
  {
    "objectID": "posts/tips_quarto/quarto_howto.html#making-custom-listings",
    "href": "posts/tips_quarto/quarto_howto.html#making-custom-listings",
    "title": "Quarto how-to",
    "section": "",
    "text": "src\n\nCreate a template with an .ejs extension\nitems stores your list items. You can loop through them. Every item has parameters corresponding to the listing fields, e.g. item.title, item.date etc. You need to wrap them in special brackets, e.g. &lt;%= item.title %&gt;\nYou can define divs, spans and other elements, and add classes to them. Then you can modify the styling using css, e.g. in your main styles.css file or another file\nTo use the template, in the listing part of the document, instead of type: default declare template: path\\to\\custom_listing_declaration.ejs"
  },
  {
    "objectID": "posts/tips_quarto/quarto_howto.html#merging-python-and-observable",
    "href": "posts/tips_quarto/quarto_howto.html#merging-python-and-observable",
    "title": "Quarto how-to",
    "section": "Merging Python and Observable",
    "text": "Merging Python and Observable\nHow to merge various engines in one notebook: https://gist.github.com/hrbrmstr/23355194d1964688596553a0e6a0050a\nThe secret is to declare the language in code such as:\n\nprint('Hello python')\n# bla = {'x_values': [0,1,2,3,4], 'y_values': [10,11,12,10,9]}\nbla0 = {'x_values': [0,1,2,3,4], 'y_values': [10,11,12,10,9]}\nbla = []\nfor i in range(len(bla0['x_values'])):\n  tmp = {}\n  for k in bla0.keys():\n    tmp[k] = bla0[k][i]\n  bla.append(tmp)\nojs_define(bla=bla)\nprint(bla)\n\nHello python\n\n\n\n\n\n[{'x_values': 0, 'y_values': 10}, {'x_values': 1, 'y_values': 11}, {'x_values': 2, 'y_values': 12}, {'x_values': 3, 'y_values': 10}, {'x_values': 4, 'y_values': 9}]\n\n\n\nbla\n\n\n\n\n\n\n\nconsole.log('hello observable js')\n\n\n\n\n\n\n\nPlot.dot(bla, {x: \"x_values\", y: \"y_values\"}).plot()"
  },
  {
    "objectID": "posts/tips_quarto/quarto_links.html",
    "href": "posts/tips_quarto/quarto_links.html",
    "title": "Various resources about quarto",
    "section": "",
    "text": "Various resources on quarto\nPorting a distill blog to quarto\nThe ultimate guide to starting a Quarto blog\nHow to style your Quarto blog without knowing a lot of HTML/CSS\nGet started with Quarto: RConf2022\nAwesome Quarto"
  },
  {
    "objectID": "posts/tips_quarto/quarto_traffic.html",
    "href": "posts/tips_quarto/quarto_traffic.html",
    "title": "Add traffic analytics to your quarto blog",
    "section": "",
    "text": "I have recently added lightweight traffic analytics to this blog. I decided not to go for Google Analytics, but use one of the free, open-source, privacy-conscious options instead. I went with GoatCounter. To set up traffic analytics with GoatCounter is quite easy:\n\nregister an account with them\nadd a JS snippet to the website you wish to track\nvoila!\n\nTo integrate the GoatCounter tracking script in the Quarto blog, I used the solution which I found on Danielle Navarro’s blog:\n\ncreate an html that will host the script, in my case it was a snippet that GoatCounter sent to me upon creating the account:\n\n&lt;script data-goatcounter=\"https://HERE_YOUR_GOATCOUNTER_ACCOUNT_NAME.goatcounter.com/count\"\n        async src=\"//gc.zgo.at/count.js\"&gt;&lt;/script&gt;\n\nput this html (in my case, traffic.html) in the main directory of my blog, in the same folder where _quarto.yml lives\nedit _quarto.yml to include the following:\n\nformat:\n  html:\n    include-after-body: traffic.html\nThat’s it! Now the GoatCounter script will be embedded in all the pages on the blog.\nIf you are using another tracking provider, Quarto has a tutorial how to switch on cookies and embed your own script."
  },
  {
    "objectID": "posts/tips_quarto/quarto_worktree.html",
    "href": "posts/tips_quarto/quarto_worktree.html",
    "title": "Fix the quarto publish gh-pages error on windows",
    "section": "",
    "text": "Sometimes quarto publish gh-pages hangs while creating the worktree.\nFor me the following worked (suggested by this tutorial and the commands quarto publish uses ).\nFirst notice the extra directory in your git repository, called 2054a64 or similar.\nThen do:\ncd 2054a64 \ngit add -Af . \ngit commit --allow-empty -m \"Semi-manual deploy\"\ngit remote -v\ngit push --force origin HEAD:gh-pages\ncd ..\ngit worktree remove 2054a64 \ngit worktree prune"
  }
]