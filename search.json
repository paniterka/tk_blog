[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "all_posts_categorized.html",
    "href": "all_posts_categorized.html",
    "title": "All posts",
    "section": "",
    "text": "Mostly pandas and matplotlib tricks.\n\n  \n    \n      \n        \n          \n            Creating colormaps in matplotlib \n            \n              (Aug 2, 2022)\n            \n          \n           cheatsheet, matplotlib \n        \n      \n      \n        \n          \n            Customizing the legend \n            \n              (Sep 27, 2022)\n            \n          \n           matplotlib \n        \n      \n      \n        \n          \n            Dealing with messy CSVs \n            \n              (Sep 16, 2022)\n            \n          \n           pandas \n        \n      \n      \n        \n          \n            Generate dictionaries from dataframes \n            \n              (Sep 16, 2022)\n            \n          \n           pandas \n        \n      \n      \n        \n          \n            Generating random days between two dates \n            \n              (Jul 30, 2022)\n            \n          \n           cheatsheet, pandas \n        \n      \n      \n        \n          \n            Installing geopandas on Windows \n            \n              (Nov 5, 2022)\n            \n          \n           pandas, geodata \n        \n      \n      \n        \n          \n            Saving a chart as a numpy array and warping it using skimage \n            \n              (Aug 3, 2022)\n            \n          \n           cheatsheet, matplotlib, numpy \n        \n      \n      \n        \n          \n            Skipping empty csv rows \n            \n              (Aug 4, 2022)\n            \n          \n           cheatsheet, pandas \n        \n      \n      \n        \n          \n            Tick formatting recipes \n            \n              (Sep 21, 2022)\n            \n          \n           matplotlib \n        \n      \n      \n        \n          \n            Using fontprops \n            \n              (Sep 27, 2022)\n            \n          \n           matplotlib \n        \n      \n      \n        \n          \n            Various Matplotlib resources \n            \n              (Aug 4, 2022)\n            \n          \n           matplotlib \n        \n      \n      \n        \n          \n            Various Pandas resources \n            \n              (Aug 4, 2022)\n            \n          \n           pandas \n        \n      \n      \n        \n          \n            Watermarks, footnotes and other annotations \n            \n              (Sep 27, 2022)\n            \n          \n           matplotlib \n        \n      \n      \n        \n          \n            Weekday names in pandas \n            \n              (Oct 8, 2022)\n            \n          \n           pandas, datetime \n        \n      \n      \n        \n          \n            Working with datetimes \n            \n              (Jul 26, 2022)\n            \n          \n           cheatsheet, pandas \n        \n      \n    \n  \n\nNo matching items"
  },
  {
    "objectID": "all_posts_categorized.html#quarto",
    "href": "all_posts_categorized.html#quarto",
    "title": "All posts",
    "section": "Quarto",
    "text": "Quarto\n\n  \n    \n      \n        \n          \n            Coupling Python and Observable using ojs_define() \n            \n              (Jul 30, 2022)\n            \n          \n           quarto \n        \n      \n      \n        \n          \n            Fix the `quarto publish gh-pages` error on windows \n            \n              (Aug 8, 2022)\n            \n          \n           quarto, git \n        \n      \n      \n        \n          \n            Quarto how-to \n            \n              (Jul 29, 2022)\n            \n          \n           cheatsheet \n        \n      \n      \n        \n          \n            Various resources about quarto \n            \n              (Aug 1, 2022)\n            \n          \n           quarto \n        \n      \n    \n  \n\nNo matching items"
  },
  {
    "objectID": "all_posts_categorized.html#other-tech-topics",
    "href": "all_posts_categorized.html#other-tech-topics",
    "title": "All posts",
    "section": "Other tech topics",
    "text": "Other tech topics\n\n\n  \n    \n      \n        \n          \n            Doing things with conda environments \n            \n              (Oct 8, 2022)\n            \n          \n           python, conda \n        \n      \n      \n        \n          \n            Poetry tips and tricks \n            \n              (Aug 18, 2022)\n            \n          \n           cheatsheet, poetry \n        \n      \n      \n        \n          \n            Style a list element to look like a table \n            \n              (Aug 5, 2022)\n            \n          \n           css \n        \n      \n      \n        \n          \n            Useful git stuff \n            \n              (Jul 26, 2022)\n            \n          \n           cheatsheet, git \n        \n      \n      \n        \n          \n            Writing EJS templates \n            \n              (Aug 5, 2022)\n            \n          \n           ejs, quarto, javascript \n        \n      \n    \n  \n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Figuring things outone post at a time",
    "section": "",
    "text": "Welcome!\nAt this point this blog is mostly just a collection of code snippets and tips for visualizing data with Python."
  },
  {
    "objectID": "index.html#latest-posts",
    "href": "index.html#latest-posts",
    "title": "Figuring things outone post at a time",
    "section": "Latest posts",
    "text": "Latest posts\n\n  \n    \n      \n        \n          \n            Installing geopandas on Windows \n            \n              (Nov 5, 2022)\n            \n          \n           pandas, geodata \n        \n      \n      \n        \n          \n            Doing things with conda environments \n            \n              (Oct 8, 2022)\n            \n          \n           python, conda \n        \n      \n      \n        \n          \n            Weekday names in pandas \n            \n              (Oct 8, 2022)\n            \n          \n           pandas, datetime \n        \n      \n      \n        \n          \n            Using fontprops \n            \n              (Sep 27, 2022)\n            \n          \n           matplotlib \n        \n      \n      \n        \n          \n            Customizing the legend \n            \n              (Sep 27, 2022)\n            \n          \n           matplotlib \n        \n      \n      \n        \n          \n            Watermarks, footnotes and other annotations \n            \n              (Sep 27, 2022)\n            \n          \n           matplotlib \n        \n      \n      \n        \n          \n            Tick formatting recipes \n            \n              (Sep 21, 2022)\n            \n          \n           matplotlib \n        \n      \n      \n        \n          \n            Generate dictionaries from dataframes \n            \n              (Sep 16, 2022)\n            \n          \n           pandas \n        \n      \n    \n  \n\nNo matching items\n\n\n\nBrowse all posts…"
  },
  {
    "objectID": "posts/mpl/colormaps.html",
    "href": "posts/mpl/colormaps.html",
    "title": "Creating colormaps in matplotlib",
    "section": "",
    "text": "import matplotlib.pyplot as plt\n%matplotlib inline"
  },
  {
    "objectID": "posts/mpl/colormaps.html#create-colormap-from-a-list-of-colors",
    "href": "posts/mpl/colormaps.html#create-colormap-from-a-list-of-colors",
    "title": "Creating colormaps in matplotlib",
    "section": "Create colormap from a list of colors",
    "text": "Create colormap from a list of colors\n\nfrom matplotlib.colors import LinearSegmentedColormap\ncustom_cmap = LinearSegmentedColormap.from_list(name=\"my_cmap\", colors=[\"green\", \"black\", \"purple\"])\ncustom_cmap\n\nmy_cmap  underbad over \n\n\n\nfrom matplotlib.colors import ListedColormap, BoundaryNorm\n\ncustom_cmap2 = ListedColormap(name=\"another_cmap\", colors=['green', 'black', 'purple'])\n\ncustom_cmap2\n\nanother_cmap  underbad over \n\n\n\n# ListedColormap with norm: \nnorm2 = BoundaryNorm([-1, -0.15, 0.15, 1], custom_cmap2.N) \n# BoundaryNorm maps values to INTEGERS instead of floats 0..1\nprint(norm2(0.5))\n\nf, ax = plt.subplots()\np = ax.imshow([[-0.5, -0.1], [0,0.1], [0.8,0.5]], cmap=custom_cmap2, norm=norm2)\nf.colorbar(mappable=p, spacing='proportional')\n\n2\n\n\n<matplotlib.colorbar.Colorbar at 0x1d1859349d0>"
  },
  {
    "objectID": "posts/mpl/colormaps.html#merge-2-colormaps",
    "href": "posts/mpl/colormaps.html#merge-2-colormaps",
    "title": "Creating colormaps in matplotlib",
    "section": "Merge 2 colormaps",
    "text": "Merge 2 colormaps\n\ncmap1 = LinearSegmentedColormap.from_list(name=\"cmap1\", colors=[\"green\", \"black\", \"purple\"])\ncmap2 = LinearSegmentedColormap.from_list(name=\"cmap2\", colors=[\"blue\", \"yellow\", \"orange\"])\n\nWith sharp edge:\n\nimport numpy as np\ncolors_cmap1 = cmap1(np.linspace(0, 1, 100))\ncolors_cmap2 = cmap2(np.linspace(0, 1, 200))\nall_colors = np.vstack((colors_cmap1, colors_cmap2))\n\ncmap_merged = LinearSegmentedColormap.from_list('merged',all_colors)\n\ncmap_merged\n\nmerged  underbad over \n\n\nWith smooth transition:\n\ncolors_cmap1 = cmap1(np.linspace(0, 1, 3))\ncolors_cmap2 = cmap2(np.linspace(0, 1, 6))\nall_colors = np.vstack((colors_cmap1, colors_cmap2))\n\ncmap_merged = LinearSegmentedColormap.from_list('merged',all_colors)\n\ncmap_merged\n\nmerged  underbad over"
  },
  {
    "objectID": "posts/mpl/font_magic.html",
    "href": "posts/mpl/font_magic.html",
    "title": "Using fontprops",
    "section": "",
    "text": "import matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/mpl/font_magic.html#use-fontprops-with-various-entities",
    "href": "posts/mpl/font_magic.html#use-fontprops-with-various-entities",
    "title": "Using fontprops",
    "section": "Use fontprops with various entities",
    "text": "Use fontprops with various entities\nDeclare fontprops:\nimport matplotlib as mpl\n\ncustom_font = mpl.font_manager.FontProperties(\n    family='Verdana', style='italic', size=14\n    )\nax.annotate('Something interesting here', \n            xy = (0.5,0.5), xycoords=ax,\n            fontproperties=custom_font,)\n\nf.suptitle('Nice title', \n            fontproperties=custom_font, )\n\nfor tick in ax.get_yticklabels():\n    tick.set_font_properties(custom_font)\n\nax.legend(handles=handles, prop=custom_font)"
  },
  {
    "objectID": "posts/mpl/font_magic.html#use-local-ttf-file-as-fontprops",
    "href": "posts/mpl/font_magic.html#use-local-ttf-file-as-fontprops",
    "title": "Using fontprops",
    "section": "Use local ttf file as fontprops",
    "text": "Use local ttf file as fontprops\nfrom pathlib import Path\n\ntitle_font = mpl.font_manager.FontProperties(\n            fname=Path(\"./Barlow/Barlow-Bold.ttf\"), size=20)"
  },
  {
    "objectID": "posts/mpl/legend.html",
    "href": "posts/mpl/legend.html",
    "title": "Customizing the legend",
    "section": "",
    "text": "Modified on: 2022-08-08, 2022-09-27"
  },
  {
    "objectID": "posts/mpl/legend.html#move-the-legend-to-top-right-corner-outside-of-the-chart-no-border",
    "href": "posts/mpl/legend.html#move-the-legend-to-top-right-corner-outside-of-the-chart-no-border",
    "title": "Customizing the legend",
    "section": "Move the legend to top right corner outside of the chart, no border",
    "text": "Move the legend to top right corner outside of the chart, no border\nax.legend(handles, labels, \n          bbox_to_anchor=[1.05,1], loc='upper left', \n          edgecolor='w', facecolor='none',\n          borderpad=0, borderaxespad=0)"
  },
  {
    "objectID": "posts/mpl/legend.html#place-the-legend-between-two-topmost-horizontal-gridlines",
    "href": "posts/mpl/legend.html#place-the-legend-between-two-topmost-horizontal-gridlines",
    "title": "Customizing the legend",
    "section": "Place the legend between two topmost horizontal gridlines",
    "text": "Place the legend between two topmost horizontal gridlines\n\nh = ax.plot(...)\n\ntop_tick = np.mean([ax.get_yticks()[-2], ax.get_yticks()[-3]])\nleft_tick = ax.get_xlim()[0]\n\nl = ax.legend(handles=[h],  \n    bbox_to_anchor=[left_tick,top_tick], bbox_transform=ax.transData, loc='center left', \n    borderpad=0.0, borderaxespad=0.5, \n    )"
  },
  {
    "objectID": "posts/mpl/mpl_numpy_warping.html",
    "href": "posts/mpl/mpl_numpy_warping.html",
    "title": "Saving a chart as a numpy array and warping it using skimage",
    "section": "",
    "text": "Sometimes we may want to create an image with plotting API of matplotlib, but then apply a transform that only works for numpy arrays (for example, skimage’s warps). This is how you do it:\n\nimport matplotlib.pyplot as plt \nimport numpy as np\n%matplotlib inline\n\nLet’s generate an example chart:\n\nx = [1,2,3]\nbars = [10,15,12]\n\nf, ax = plt.subplots(dpi=100)\n# when using plt.subplots, the canvas and renderer get created automatically \nax.bar(x, bars);\n\n\n\n\n\nExport the figure to a numpy array\nMethod 1 src\n\ns, (width, height) = f.canvas.print_to_buffer()\nrgba = np.frombuffer(s, np.uint8).reshape((height, width, 4))\nplt.imshow(rgba, aspect='equal');\n\n\n\n\n\nprint(type(rgba))\nprint(rgba.shape)\n\n<class 'numpy.ndarray'>\n(400, 600, 4)\n\n\nMethod 2 src\n\nrgba = np.asarray(f.canvas.buffer_rgba())\nplt.imshow(rgba);\n\n\n\n\n\nprint(type(rgba))\nprint(rgba.shape)\n\n<class 'numpy.ndarray'>\n(400, 600, 4)\n\n\n\n\nRemove the alpha channel in a numpy array (RGBA->RGB)\nTo remove the alpha channel it’s enough to run: src\n\nrgb = rgba[:,:,:3]\n\nThe resulting chart is the same (our transparency is anyway white)\n\nplt.imshow(rgb);\n\n\n\n\nBoth methods respect the dpi set when creating the figure using plt.subplots\n\n\nWarping images using skimage\nNow we can warp the image:\n\nfrom skimage.transform import swirl\n\nswirled = swirl(rgb, rotation=0, strength=30, radius=120)\n\n\nf, ax = plt.subplots(ncols = 2, figsize=(10,4))\n\nax[0].imshow(rgb, aspect='equal')\nax[0].set_title('original')\n\nax[1].imshow(swirled, aspect='equal')\nax[1].set_title('warped')\n\n[a.axis('off') for a in ax];\n\n\n\n\nMore on skimage transforms: https://scikit-image.org/docs/stable/api/skimage.transform.html"
  },
  {
    "objectID": "posts/mpl/tick_formatting.html",
    "href": "posts/mpl/tick_formatting.html",
    "title": "Tick formatting recipes",
    "section": "",
    "text": "mpl gallery about ticks\nmpl ticker API"
  },
  {
    "objectID": "posts/mpl/tick_formatting.html#default-tick-formatter",
    "href": "posts/mpl/tick_formatting.html#default-tick-formatter",
    "title": "Tick formatting recipes",
    "section": "Default tick formatter",
    "text": "Default tick formatter\nfrom matplotlib.ticker import ScalarFormatter\nax.xaxis.set_major_formatter(ScalarFormatter())"
  },
  {
    "objectID": "posts/mpl/tick_formatting.html#format-string-as-usually",
    "href": "posts/mpl/tick_formatting.html#format-string-as-usually",
    "title": "Tick formatting recipes",
    "section": "Format string as usually",
    "text": "Format string as usually\nfrom matplotlib.ticker import StrMethodFormatter\nax.xaxis.set_major_formatter(StrMethodFormatter('{x:.1f}'))"
  },
  {
    "objectID": "posts/mpl/tick_formatting.html#ticks-in-a-scientificengineering-notation",
    "href": "posts/mpl/tick_formatting.html#ticks-in-a-scientificengineering-notation",
    "title": "Tick formatting recipes",
    "section": "Ticks in a scientific/engineering notation",
    "text": "Ticks in a scientific/engineering notation\nfrom matplotlib.ticker import EngFormatter\nax.xaxis.set_major_formatter(EngFormatter(sep='')) # no unit, no distance to the multiplier \nax.xaxis.set_major_formatter(EngFormatter(unit='Hz')) \nsrc"
  },
  {
    "objectID": "posts/mpl/tick_formatting.html#percent-formatter-that-does-the-scaling-too",
    "href": "posts/mpl/tick_formatting.html#percent-formatter-that-does-the-scaling-too",
    "title": "Tick formatting recipes",
    "section": "Percent formatter that does the scaling too",
    "text": "Percent formatter that does the scaling too\nfrom matplotlib.ticker import PercentFormatter\nvalue_100perc = 2.5 # data value corresponding to the 100%\nax.xaxis.set_major_formatter(PercentFormatter(xmax=value_100perc))"
  },
  {
    "objectID": "posts/mpl/tick_formatting.html#lambda-formatter-func-formatter",
    "href": "posts/mpl/tick_formatting.html#lambda-formatter-func-formatter",
    "title": "Tick formatting recipes",
    "section": "Lambda formatter (func formatter)",
    "text": "Lambda formatter (func formatter)\nOption 1:\nfrom matplotlib import ticker \n\n@ticker.FuncFormatter\ndef custom_formatter(x, pos):\n    return f'[{x:.2f}]'\n\nax.xaxis.set_major_formatter(custom_formatter)\nOption 2:\nfrom matplotlib.ticker import FuncFormatter \n\ncustom_formatter = lambda x, pos: f'[{x:.2f}]'\nax.xaxis.set_major_formatter(FuncFormatter(custom_formatter))\nsrc"
  },
  {
    "objectID": "posts/mpl/tick_formatting.html#space-as-a-separator-between-thousands",
    "href": "posts/mpl/tick_formatting.html#space-as-a-separator-between-thousands",
    "title": "Tick formatting recipes",
    "section": "Space as a separator between thousands",
    "text": "Space as a separator between thousands\n\nimport matplotlib.pyplot as plt \n\ny = [0, 1e4, 2.3e4, 3.12e4]\nx = [2000, 2010, 2020, 2030]\n\nUse the FuncFormatter, which requires a function of a form:\ndef my_func(x,pos): \n    # blablabla \n    return formatted_x_string\nNow implement the formatter. We want every 3 digits separated by a space, and our labels to be integers (won’t work for floats). We will use format(), which accepts parameter ,d producing comma-separated notation, and replace the commas with spaces.\nThe formatter can be applied to each axis separately.\nfrom matplotlib.ticker import FuncFormatter\nformat_spaces = lambda x, pos: format(int(round(x)), ',d').replace(',',' ')\nax.yaxis.set_major_formatter(FuncFormatter(format_spaces))\n\nf, ax = plt.subplots()\nax.plot(x,y,marker='o')\n\nfrom matplotlib.ticker import FuncFormatter\nformat_spaces = lambda x, pos: format(int(round(x)), ',d').replace(',',' ')\nax.yaxis.set_major_formatter(FuncFormatter(format_spaces))"
  },
  {
    "objectID": "posts/mpl/various_resources.html",
    "href": "posts/mpl/various_resources.html",
    "title": "Various Matplotlib resources",
    "section": "",
    "text": "Tueplots\n\nsets of rcParams as dictionaries adapted to various styling requirements\nconfiguration for ML conferences: AISTATS 2022, method-of-machine-learning group in Tübingen, ICML 2022, JMLR 2001, Neurips 2021, Neurips 2022\n\nSciencePlots\n\nScience, IEEE\ncolor and line style cyclers for academic publishing\n\nMetBrewer\n\ncollection of color palettes inspired by the works of art from Met Gallery\ninstall via pip install git+https://github.com/BlakeRMills/MetBrewer.git#subdirectory=Python src\nnot all the pallettes from R are ported into Python"
  },
  {
    "objectID": "posts/mpl/various_resources.html#matplotlib-extensions",
    "href": "posts/mpl/various_resources.html#matplotlib-extensions",
    "title": "Various Matplotlib resources",
    "section": "Matplotlib extensions",
    "text": "Matplotlib extensions\n\nCookiecutter repository for new extensions\nOfficial list of 3rd party packages"
  },
  {
    "objectID": "posts/mpl/various_resources.html#helper-modules",
    "href": "posts/mpl/various_resources.html#helper-modules",
    "title": "Various Matplotlib resources",
    "section": "Helper modules",
    "text": "Helper modules\n\ncolour\n\nsimple way to manipulate color representations"
  },
  {
    "objectID": "posts/mpl/watermarks_footnotes.html",
    "href": "posts/mpl/watermarks_footnotes.html",
    "title": "Watermarks, footnotes and other annotations",
    "section": "",
    "text": "import matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/mpl/watermarks_footnotes.html#add-a-watermark",
    "href": "posts/mpl/watermarks_footnotes.html#add-a-watermark",
    "title": "Watermarks, footnotes and other annotations",
    "section": "Add a watermark",
    "text": "Add a watermark\nSometimes you want a big fat text on your chart that says that these are preliminary results.\n\nf, ax = plt.subplots()\n\nimport matplotlib.patheffects as path_effects\n\nwatermark_text = 'draft'\nt = ax.text(0.5, 0.5, watermark_text, transform=ax.transAxes,\n        fontsize=80, color='white', alpha=0.3,  weight=\"bold\", \n        ha='center', va='center', rotation='30')\nt.set_path_effects([path_effects.Stroke(linewidth=3, foreground='lightgray')])\n\n\n\n\nChange color='white' to make it colorful. The edge color is encoded in set_path_effects as foreground."
  },
  {
    "objectID": "posts/mpl/watermarks_footnotes.html#add-a-footnote",
    "href": "posts/mpl/watermarks_footnotes.html#add-a-footnote",
    "title": "Watermarks, footnotes and other annotations",
    "section": "Add a footnote",
    "text": "Add a footnote\n\nBottom right\n\nf, ax = plt.subplots()\n\nfootnote = [\n    'Data source: XY',\n    'Author: TK'\n]\n\nax.annotate('\\n'.join(footnote), \n            xy = (1.05,0), xycoords=ax, ha='left', va='bottom',\n            fontsize=8, style='italic', \n            bbox=dict(boxstyle='square,pad=0.0',fc='none', ec='none')\n        )\n\nText(1.05, 0, 'Data source: XY\\nAuthor: TK')\n\n\n\n\n\nThe footnote is positioned relative to the axes (xycoords+ha+va). The pad is removed. Aligning to bottom makes it robust for multiline entries.\n\n\nBottom left under the chart\n\nf, ax = plt.subplots()\n\nfootnote = [\n    'Data source: XY',\n    'Author: TK'\n]\n\nax.annotate('|'.join(footnote), \n            xy = (0,-0.25), xycoords=ax, ha='left', va='top',\n            fontsize=8, style='italic', \n            bbox=dict(boxstyle='square,pad=0.0',fc='none', ec='none')\n        )\n\nText(0, -0.25, 'Data source: XY|Author: TK')\n\n\n\n\n\n\nf, ax = plt.subplots()\n\nfootnote = [\n    'Data source: XY',\n    'Author: TK'\n]\n\nax.annotate(footnote[0], \n            xy = (0,-0.25), xycoords=ax, ha='left', va='top',\n            fontsize=8, style='italic', \n            bbox=dict(boxstyle='square,pad=0.0',fc='none', ec='none')\n        )\nax.annotate(footnote[1], \n            xy = (1,-0.25), xycoords=ax, ha='right', va='top',\n            fontsize=8, style='italic', \n            bbox=dict(boxstyle='square,pad=0.0',fc='none', ec='none')\n        )\n\nText(1, -0.25, 'Author: TK')"
  },
  {
    "objectID": "posts/other_tech/conda_environments.html",
    "href": "posts/other_tech/conda_environments.html",
    "title": "Doing things with conda environments",
    "section": "",
    "text": "Update the Python version\nIt’s scary, but needs to be done sometimes (e.g. when you have a perfectly working old environment built on Python 3.6, but then one dependency stops behaving and requires P3.8+).\nIf in a conda environment:\nconda activate my_env\nconda install -c anaconda python=<version>\nsrc\n\n\nClone an environment\nIf you want to make a clone of the environment for a backup purpose:\nconda create --name <target_environment> --clone <source_environment> \nIf you want to clone the base:\nconda create --name <myenv> --clone base\n\n\nSolve the libarchive error\nhttps://github.com/ContinuumIO/anaconda-issues/issues/11104#issuecomment-510285329\n\ninstall miniconda to a separate folder. Tell it not to run conda init\nactivate that installation with source /path/to/new/miniconda/bin/activate\nrun conda install -p /path/to/broken/anaconda –force python-libarchive-c conda-package-handling libarchive\n\nSimilar here: https://github.com/conda/conda/issues/7714#issuecomment-417553149\n\n\nInstall geopandas at start\nhttps://stackoverflow.com/questions/61927004/conda-install-some-package-hangs-with-solving-environment-failed\n\n\nBasics\nList environments:\nconda info --envs \nInstall ipykernel pointing to a venv:\npip install ipykernel \npython -m ipykernel install --name my_venv"
  },
  {
    "objectID": "posts/other_tech/ejs.html",
    "href": "posts/other_tech/ejs.html",
    "title": "Writing EJS templates",
    "section": "",
    "text": "When writing custom templates, categories are joined into string which is comma-separated but has no spaces between the categories. Because of that, if the text is wider than its container, it will overflow instead of being wrapped. One solution is to add spaces using String.replace():\n<%= String(item.categories).replace(/,/g, ', ') %>"
  },
  {
    "objectID": "posts/other_tech/poetry.html",
    "href": "posts/other_tech/poetry.html",
    "title": "Poetry tips and tricks",
    "section": "",
    "text": "Install ipykernel as development dependency:\npoetry add -D ipykernel\nRegister the ipykernel:\npoetry run python -m ipykernel install --user --name my_kernel\nCheck that the kernel is registered:\njupyter kernelspec list"
  },
  {
    "objectID": "posts/other_tech/poetry.html#install-the-main-package-in-the-ipykernel-so-that-its-available-from-anywhere",
    "href": "posts/other_tech/poetry.html#install-the-main-package-in-the-ipykernel-so-that-its-available-from-anywhere",
    "title": "Poetry tips and tricks",
    "section": "Install the main package in the ipykernel so that it’s available from anywhere",
    "text": "Install the main package in the ipykernel so that it’s available from anywhere\nPoetry by default will try to do it, but Jupyter will not recognize this. You need to add a setup.py alongside your __init__.py:\nfrom setuptools import setup, find_packages\n\nsetup(\n    name='name_of_your_package',\n    version='0.1.0',\n    packages=find_packages(include=['name_of_your_package', 'name_of_your_package.*'])\n)"
  },
  {
    "objectID": "posts/other_tech/poetry.html#see-the-location-of-the-current-venv",
    "href": "posts/other_tech/poetry.html#see-the-location-of-the-current-venv",
    "title": "Poetry tips and tricks",
    "section": "See the location of the current venv:",
    "text": "See the location of the current venv:\npoetry env info --path"
  },
  {
    "objectID": "posts/other_tech/poetry.html#managing-different-poetry-environments-in-different-branches",
    "href": "posts/other_tech/poetry.html#managing-different-poetry-environments-in-different-branches",
    "title": "Poetry tips and tricks",
    "section": "Managing different poetry environments in different branches",
    "text": "Managing different poetry environments in different branches\nBy default, Poetry will create one global environment for a given project name. This can be problematic when you use different dependencies on different branches, but within the same project.\n\nSolution 1: recreate the environment at switch\nSwitch branches and recreate the environment from scratch:\npoetry env list\npoetry env remove env_name_like_listed_above\npoetry lock\npoetry install \nor\npoetry install --remove-untracked\n\n\nSolution 2: keep branches in separate directories and make poetry create local environments\nClone each branch into a separate local directory. To make poetry create separate environments w/o having to rename the project name in pyproject.toml, run:\n\nfor all the projects:\n\npoetry config virtualenvs.in-project true\n\nonly for those projects - run separately in each directory\n\npoetry config virtualenvs.in-project true --local\nAnd then run:\npoetry lock \npoetry install\nLock is important to create a new venv.\nTo see the current config:\npoetry config --list\nsrc1 src2 src3\nThen mount Ipython kernel in each environment separately."
  },
  {
    "objectID": "posts/other_tech/table_like_li_css.html",
    "href": "posts/other_tech/table_like_li_css.html",
    "title": "Style a list element to look like a table",
    "section": "",
    "text": "The HTML part\n<div class=\"custom_listing\">\n<ul>\n<li>\n    <span class=\"li-contents-container\">\n        <span class=\"left-container\">\n            Here the left part of the list element. Can consist of spans.\n        </span>\n        <span class=\"right-container\">\n            Something that will be aligned to the right.\n        </span>\n    </span>\n</li>\n</ul>\n</div>\n\n\nThe CSS part\n.custom_listing li .li-contents-container{\n    display: flex; \n    align-items: center;\n}\n\n.custom_listing .left-container {\n    width: 70%;\n    margin-right: auto;\n}\n\n.custom_listing .right-container {\n    max-width: 25%;\n    margin-left: auto; \n    text-align: right;\n}\n\n\nRemark\nHaving a parent li-contents-container is crucial to be able to display a bullet point or another symbol for each <li> item.\nsrc"
  },
  {
    "objectID": "posts/other_tech/useful_git.html",
    "href": "posts/other_tech/useful_git.html",
    "title": "Useful git stuff",
    "section": "",
    "text": "Because every now and then there is this thing you need to do with git, but because you do it not so often, you have to google it for like 30 sec."
  },
  {
    "objectID": "posts/other_tech/useful_git.html#branches",
    "href": "posts/other_tech/useful_git.html#branches",
    "title": "Useful git stuff",
    "section": "Branches",
    "text": "Branches\nTo create a new completely empty branch:\ngit switch --orphan <new branch>\ngit commit --allow-empty -m \"Initial commit on orphan branch\"\ngit push -u origin <new branch>\nsrc Article on branches\nTo pull a new branch from the server without touching the current branch: git fetch <remote_name> <branch_name> which in most cases is src\ngit fetch origin <branch_name>"
  },
  {
    "objectID": "posts/other_tech/useful_git.html#unstaging-files",
    "href": "posts/other_tech/useful_git.html#unstaging-files",
    "title": "Useful git stuff",
    "section": "Unstaging files",
    "text": "Unstaging files\nhttps://sethrobertson.github.io/GitFixUm/fixup.html\n\nadded but not committed\n\n\ncommitted but not pushed\nhttps://stackoverflow.com/a/15321456\ngit reset --soft HEAD^ \ngit reset HEAD path/to/unwanted_file\ngit commit -c ORIG_HEAD \nThe last command will recommit with the original commit message"
  },
  {
    "objectID": "posts/pandas/generate_fake_dates_in_pandas.html",
    "href": "posts/pandas/generate_fake_dates_in_pandas.html",
    "title": "Generating random days between two dates",
    "section": "",
    "text": "import pandas as pd \nimport numpy as np"
  },
  {
    "objectID": "posts/pandas/generate_fake_dates_in_pandas.html#generate-all-days-between-two-dates",
    "href": "posts/pandas/generate_fake_dates_in_pandas.html#generate-all-days-between-two-dates",
    "title": "Generating random days between two dates",
    "section": "Generate all days between two dates:",
    "text": "Generate all days between two dates:\n\npd.date_range(start_date, end_date, freq='D')\n\nDatetimeIndex(['2010-03-23', '2010-03-24', '2010-03-25', '2010-03-26',\n               '2010-03-27', '2010-03-28', '2010-03-29', '2010-03-30',\n               '2010-03-31', '2010-04-01',\n               ...\n               '2013-07-10', '2013-07-11', '2013-07-12', '2013-07-13',\n               '2013-07-14', '2013-07-15', '2013-07-16', '2013-07-17',\n               '2013-07-18', '2013-07-19'],\n              dtype='datetime64[ns]', length=1215, freq='D')"
  },
  {
    "objectID": "posts/pandas/generate_fake_dates_in_pandas.html#generate-n-dates-equally-spaced",
    "href": "posts/pandas/generate_fake_dates_in_pandas.html#generate-n-dates-equally-spaced",
    "title": "Generating random days between two dates",
    "section": "Generate N dates equally spaced:",
    "text": "Generate N dates equally spaced:\n\nN = 4\n\npd.date_range(start_date, end_date, periods=N).normalize()\n\nDatetimeIndex(['2010-03-23', '2011-05-01', '2012-06-09', '2013-07-19'], dtype='datetime64[ns]', freq=None)"
  },
  {
    "objectID": "posts/pandas/generate_fake_dates_in_pandas.html#generate-a-random-subsample-of-n-dates-between-the-dates",
    "href": "posts/pandas/generate_fake_dates_in_pandas.html#generate-a-random-subsample-of-n-dates-between-the-dates",
    "title": "Generating random days between two dates",
    "section": "Generate a random subsample of N dates between the dates",
    "text": "Generate a random subsample of N dates between the dates\nMethod 1 & 2 require to generate the whole date range first, then sample from it. Method 3 & 4 leverage numpy generators and construct dates out of generated numbers. Method 2 doesn’t require explicitly importing numpy. Method 4 gives you the times for free as well and seems the fastest according to the benchmark in the original SO thread\n\nMethod 1:\nnp.random.choice src\n\n# old syntax\n\nN = 4\n\npd.Series(\n    np.random.choice(\n        pd.date_range(start_date, end_date), \n        N, \n        replace=True # replace=True -> 1 value can appear multiple times\n    )\n) \n\n0   2010-12-07\n1   2010-05-20\n2   2011-12-17\n3   2013-02-24\ndtype: datetime64[ns]\n\n\n\n# new syntax\n\nrng = np.random.default_rng()\n\nN = 4\n\npd.Series(\n    rng.choice(\n        pd.date_range(start_date, end_date), \n        N, \n        replace=True # replace=True -> 1 value can appear multiple times\n    )\n) \n\n0   2013-03-16\n1   2010-11-18\n2   2012-05-27\n3   2011-03-24\ndtype: datetime64[ns]\n\n\n\n\nMethod 2:\npd.Series.sample()\n\nN = 4\n\npd.Series(\n    pd.date_range(start_date, end_date, freq='D')\n)\\\n.sample(N, replace=True)\\\n.reset_index(drop=True)\n\n0   2012-05-05\n1   2012-10-20\n2   2013-02-04\n3   2011-01-03\ndtype: datetime64[ns]\n\n\n\n\nMethod 3:\npd.to_timedelta\n\n# old syntax\n\nN = 4\n\nmax_days = (pd.to_datetime(end_date) - pd.to_datetime(start_date)).days\ndelta_days = pd.to_timedelta(\n    np.random.randint(0, max_days+1, N), \n    unit='D')\n\npd.to_datetime(start_date) + delta_days\n\nDatetimeIndex(['2013-05-10', '2011-07-19', '2011-05-14', '2013-01-30'], dtype='datetime64[ns]', freq=None)\n\n\n\n# new syntax\n\nrng = np.random.default_rng()\n\nN = 4\n\nmax_days = (pd.to_datetime(end_date) - pd.to_datetime(start_date)).days\ndelta_days = pd.to_timedelta(\n    rng.integers(0, max_days, size=N, endpoint=True), \n    unit='D')\n\npd.to_datetime(start_date) + delta_days\n\nDatetimeIndex(['2013-02-17', '2012-02-21', '2011-04-13', '2013-02-20'], dtype='datetime64[ns]', freq=None)\n\n\n\n\nMethod 4:\nunix timestamps src\n\n# old syntax\n\nN = 4\n\nstart_u = pd.to_datetime(start_date).value//int(1e9)\nend_u = pd.to_datetime(end_date).value//int(1e9)\npd.to_datetime(np.random.randint(start_u, end_u, N), unit='s').normalize()\n\nDatetimeIndex(['2010-07-15', '2011-05-11', '2010-10-30', '2010-05-19'], dtype='datetime64[ns]', freq=None)\n\n\n\n# new syntax\n\nrng = np.random.default_rng()\n\nN = 4\n\nstart_u = pd.to_datetime(start_date).value//int(1e9)\nend_u = pd.to_datetime(end_date).value//int(1e9)\npd.to_datetime(rng.integers(start_u, end_u, N, endpoint=True), unit='s').normalize()\n\nDatetimeIndex(['2011-03-22', '2011-08-23', '2012-12-26', '2010-08-05'], dtype='datetime64[ns]', freq=None)"
  },
  {
    "objectID": "posts/pandas/installing_geopandas.html",
    "href": "posts/pandas/installing_geopandas.html",
    "title": "Installing geopandas on Windows",
    "section": "",
    "text": "The first time I tried to make geopandas work on Windows, I spent 2 days struggling. The official way to install it using conda never worked for me. Finally I found a way, but I was terrified of having to do it again, so I tried to keep and reuse this virtual environment as long as I can. Unfortunately, some time ago I had to nuke my whole Anaconda installation in order to upgrade the base Python and lost the environment. Luckily, I found this excellent tutorial by Francis Adrian Viernes that helped me set up a geopandas environment in no time!\nHere are the steps, how they worked for me:\n\nCreate a new environment (I used conda for this)\nKnow your Python version (your Python version is the same as your CPython version) by running python -V in your environment. Alternatively you can run conda info and look at user-agent.\nInstall the latest MS Visual C++ binaries for the X64 architecture (permalink to the .exe)\nDownload precompiled wheels for geopandas dependencies from Archived: Unofficial Windows Binaries for Python Extension Packages. For a 64-bit system, choose win_amd64 suffix. Pick the wheel for your Python version, e.g. for Python 3.9 take a wheel described as cp39. Do NOT change the file name.\n\n\n\nGDAL\nPyProj\nFiona\nShapely\n\n\n\nInstall the wheel in exactly the same sequence as listed: GDAL -> PyProj -> Fiona -> Shapely with pip. Open conda shell, navigate to the folder where your wheels are and for each wheel, run:\n\npip install relevant_file_name.whl\n\nIn the last step, install geopandas with pip from pypi (there is no wheel available):\n\npip install geopandas\nThis recipe worked for Windows 10 Professional, Python 3.9.12, conda 4.12.0, pip 22.3, GDAL 3.4.3, PyProj 3.3.1, Fiona 1.8.21, Shapely 1.8.2, geopandas 0.12.1."
  },
  {
    "objectID": "posts/pandas/pandas_dictionaries.html",
    "href": "posts/pandas/pandas_dictionaries.html",
    "title": "Generate dictionaries from dataframes",
    "section": "",
    "text": "Sometimes it is useful to use dictionaries in pandas workflows. For example, when using a df.replace() or df.rename() command. Sometimes it is useful when those dictionaries are generated from another dataframe.\nConcrete example could be working with messy country names. Let’s say I have a dataframe containing some values per country:\ndf = pd.DataFrame([['Poland', 'Jan Nowak', 3], ['POL', 'Martyna Kowalska', 15], ['PL', 'Joanna Byk', 19]], \n        columns=['country', 'athlete', 'score'])\nand another dataframe which contains attribution of a messy country name to a proper country name:\ncountries = pd.DataFrame(['Poland', 'PL'], ['POL', 'PL'], ['PL', 'PL'], columns=['messy', 'proper'])\nHere countries is generated programmatically, but the benefit of using a countries dataframe is that it can be maintained in a form of an external csv or xlsx, which contains a hand-curated list of synonyms.\nWhat we want to get is a dictionary of a form: {'messy_name': 'proper_name'}.\nWe can achieve it in a following way:\nnames_dict = countries.drop_duplicates().set_index('messy')['proper'].to_dict()\nWe need to drop duplicates, otherwise we will only get the first entry (keys are unique in a dictionary). Optimally we would do it at the earlier stage.\nTo clean the messy names, we can then do:\ndf['country'].replace(names_dict)\nto get a disambiguated column. We can overwrite the original or create a new column, e.g. country_clean."
  },
  {
    "objectID": "posts/pandas/reading_messy_csvs.html",
    "href": "posts/pandas/reading_messy_csvs.html",
    "title": "Dealing with messy CSVs",
    "section": "",
    "text": "In the wild, some data come as messy CSVs or TXT files. Luckily, we can customize the pd.read_csv() to deal with many surprises that await us."
  },
  {
    "objectID": "posts/pandas/reading_messy_csvs.html#configure-the-file-imports",
    "href": "posts/pandas/reading_messy_csvs.html#configure-the-file-imports",
    "title": "Dealing with messy CSVs",
    "section": "Configure the file imports",
    "text": "Configure the file imports\nTo set the explicit file encoding, for a case when the non-Latin characters were saved in a weird way. Pick your favorite one (ansi, utf-8 etc.)\npd.read_csv('messyfile.txt', encoding='ansi')\nDelimiter other than a comma. Common delimiters are: \\t for tab, | for pipe etc.\npd.read_csv('messyfile.tsv', delimiter='\\t')\npd.read_csv('messyfile.tsv', sep='\\t')\nYour CSV has a commentary on top of your data and you know how many lines there are (here, 9 lines of commentary):\npd.read_csv('messyfile.csv', skiprows=9)\nYour CSV has a commentary above/in/below your data and it is preceded with a #:\npd.read_csv('messyfile.csv', comment='#')\nYour CSV has data which look like NaN, but are actually proper data points, e.g. a shortcut NA for North America: (this will also switch off all the other ways of fishing out the NaN values)\npd.read_csv('messyfile.csv', na_filter=False)\nYour CSV has textual data which contain a valid double-quote character as part of the string which has been escaped with \\:\npd.read_csv('messyfile.csv', escapechar='\\')\nYou know that the table is at the beginning of the file and it takes 11 lines, and below the table there is an unknown volume of garbage/commentary:\npd.read_csv('messyfile.csv', nrows=11)"
  },
  {
    "objectID": "posts/pandas/reading_messy_csvs.html#how-to-snoop-the-file-before-reading",
    "href": "posts/pandas/reading_messy_csvs.html#how-to-snoop-the-file-before-reading",
    "title": "Dealing with messy CSVs",
    "section": "How to snoop the file before reading",
    "text": "How to snoop the file before reading\nSometimes the mess is big and we want to snoop the file first and decide between an import scenario.\nFor example, we have a set of csvs and the headers are missing in some of them. The columns should be the same in each file. We know what the default header should be. We can store it in a variable:\nheaderline = 'col1,col2,col3'\nheader_names = headerline.split(',')\nIf your column names are messy, you may want to strip them from whitespace etc. in this step.\nThen we can open each csv file separately, snoop the beginning and decide on the import scenario. It is important to move back the cursor to the beginning after performing a read operation.\nwith open('single_file.csv') as tmp_file:\n\n  # snoop the first line and move the file pointer back to the file beginning \n  x = tmp_file.tell() # get the initial position \n  first_line = tmp_file.readline().decode('utf-8') # snoop \n  tmp_file.seek(x) # move the pointer back to the iniital position \n  \n  # do something depending on what we found out \n  if first_line != headerline: # if the headerline is missing at the beginning \n      df_tmp = pd.read_csv(tmp_file, delimiter=',', \n                            header=0, names=header_names) # read header manually\n      # here you can do something else to your data to clean it\n  else: \n      df_tmp = pd.read_csv(tmp_file, delimiter=',') # read as usual \nI had a real case like this, where in the bunch of CSVs the header was sometimes above and sometimes below the data table. I want to believe that a person who created this data set must have had a very very bad day."
  },
  {
    "objectID": "posts/pandas/reading_messy_csvs.html#to-merge-the-csvs-into-one-big-dataframe",
    "href": "posts/pandas/reading_messy_csvs.html#to-merge-the-csvs-into-one-big-dataframe",
    "title": "Dealing with messy CSVs",
    "section": "To merge the csvs into one big dataframe",
    "text": "To merge the csvs into one big dataframe\nThe best is to use pd.concat():\ndf_list = []\nfor f in list_of_files: \n  df_tmp = pd.read_csv(f) # here you can use your customized read function like in the snooping example\n  df_list.append(df_tmp)\nbig_df = pd.concat(df_list).reset_index()\nRemember to reset_index(), as all the dataframes will come with their own index, which may screw up your loc operations later on if you leave duplicate indices."
  },
  {
    "objectID": "posts/pandas/skipping_arbitrary_empty_rows.html",
    "href": "posts/pandas/skipping_arbitrary_empty_rows.html",
    "title": "Skipping empty csv rows",
    "section": "",
    "text": "Let’s say you got a series of csv files which contain tabular data, but there is a certain amount of commentary above the table:\nComment line 1 \nComment line 2 \nComment line 3 \n\ncol1, col2, col3 \n10, 12, 13\n21, 20, 22\nPandas accepts also file objects as an input, so you can travel through the lines until you find a separating line (or another condition) and then proceed with pd.read_csv:\nimport pandas as pd\n\nf = open(\"data.csv\")\nwhile f.readline() != '\\n':\n    pass\n\ndf = pd.read_csv(f, header=None)\nf.close()\nAs suggested in src"
  },
  {
    "objectID": "posts/pandas/various_pandas_resources.html",
    "href": "posts/pandas/various_pandas_resources.html",
    "title": "Various Pandas resources",
    "section": "",
    "text": "Data manipulation R-Python conversion guide\nRPY2 github and docs"
  },
  {
    "objectID": "posts/pandas/weekday_weekname.html",
    "href": "posts/pandas/weekday_weekname.html",
    "title": "Weekday names in pandas",
    "section": "",
    "text": "Pandas offers you a functionality to read the day of the week out of a datetime column: dt.weekday. However these are values ranging from 0..6. Is there a better way to convert them to human-readable days rather than using our real-world knowledge? (yes, there is!)\n\nimport pandas as pd \n\n\ngenerate the weekday names in a given locale\nWe can use the .dt.day_name() function to generate named days. This function alone gets us only to discover that 2018-01-01 was a Monday. But we can do the following:\n\nGenerate 7 consecutive dates with pd.date_range()\nFor each of them, read out its .dt.weekday\nFor each of them, read out its .dt.day_name()\nIgnore/drop the first column and use the dataframe as a mapping between the integer denoting a day and its human-readable form.\n\nBonus: we can generate named days in a given locale. So for example to obtain a mapping between integers, day names in English, day names in German:\n\ns = pd.DataFrame(pd.date_range(start='2018-01-01', freq='D', periods=7), columns=['date'])\ns['weekday'] = s['date'].dt.weekday\ns['weekday_en'] = s['date'].dt.day_name()\ns['weekday_de'] = s['date'].dt.day_name(locale='de')\ns \n\n\n\n\n\n  \n    \n      \n      date\n      weekday\n      weekday_en\n      weekday_de\n    \n  \n  \n    \n      0\n      2018-01-01\n      0\n      Monday\n      Montag\n    \n    \n      1\n      2018-01-02\n      1\n      Tuesday\n      Dienstag\n    \n    \n      2\n      2018-01-03\n      2\n      Wednesday\n      Mittwoch\n    \n    \n      3\n      2018-01-04\n      3\n      Thursday\n      Donnerstag\n    \n    \n      4\n      2018-01-05\n      4\n      Friday\n      Freitag\n    \n    \n      5\n      2018-01-06\n      5\n      Saturday\n      Samstag\n    \n    \n      6\n      2018-01-07\n      6\n      Sunday\n      Sonntag\n    \n  \n\n\n\n\nWe can add variations of weekday names, such as:\n\ns['weekday_short'] = s['weekday_en'].apply(lambda x: x[0:3]).str.upper()\n\nWe can also create a dictionary:\n\nweekday_dict = s[['weekday', 'weekday_short']].set_index('weekday_short')['weekday'].to_dict()\nweekday_dict\n\n{'MON': 0, 'TUE': 1, 'WED': 2, 'THU': 3, 'FRI': 4, 'SAT': 5, 'SUN': 6}"
  },
  {
    "objectID": "posts/pandas/working_with_datetimes.html",
    "href": "posts/pandas/working_with_datetimes.html",
    "title": "Working with datetimes",
    "section": "",
    "text": "Working with datetimes\n\nimport pandas as pd\n\n\nTo extract just date from a full datetime\n\ns = pd.Series(pd.date_range(\"20130101\", periods=4, freq='H'))\ns\n\n0   2013-01-01 00:00:00\n1   2013-01-01 01:00:00\n2   2013-01-01 02:00:00\n3   2013-01-01 03:00:00\ndtype: datetime64[ns]\n\n\nKeep just the date:\n\ns.dt.date\n\n0    2013-01-01\n1    2013-01-01\n2    2013-01-01\n3    2013-01-01\ndtype: object\n\n\nKeep just the date as datetime object:\n\ns.dt.date.astype('datetime64')\n\n0   2013-01-01\n1   2013-01-01\n2   2013-01-01\n3   2013-01-01\ndtype: datetime64[ns]\n\n\nKeep just the date by resetting the timestamp:\n\ns.dt.normalize()\n\n0   2013-01-01\n1   2013-01-01\n2   2013-01-01\n3   2013-01-01\ndtype: datetime64[ns]\n\n\nKeep the date with a particular formatting:\n\ns.dt.strftime(\"%Y/%m/%d\")\n\n0    2013/01/01\n1    2013/01/01\n2    2013/01/01\n3    2013/01/01\ndtype: object\n\n\nLinks:\n- source\n- .dt docs"
  },
  {
    "objectID": "posts/tips_quarto/ojs_define_series.html",
    "href": "posts/tips_quarto/ojs_define_series.html",
    "title": "Coupling Python and Observable using ojs_define()",
    "section": "",
    "text": "See src and this Issue\n\nimport pandas as pd \nmy_variable = pd.Series([0,1,2,3])\nojs_define(my_variable = pd.DataFrame(my_variable)) # this works\nojs_define(my_variable2 = my_variable.tolist()) # this works\n# ojs_define(my_variable = my_variable) # this doesn't\n\n\n\n\n\n\n\n\nmy_variable"
  },
  {
    "objectID": "posts/tips_quarto/quarto_howto.html",
    "href": "posts/tips_quarto/quarto_howto.html",
    "title": "Quarto how-to",
    "section": "",
    "text": "src\n\nCreate a template with an .ejs extension\nitems stores your list items. You can loop through them. Every item has parameters corresponding to the listing fields, e.g. item.title, item.date etc. You need to wrap them in special brackets, e.g. <%= item.title %>\nYou can define divs, spans and other elements, and add classes to them. Then you can modify the styling using css, e.g. in your main styles.css file or another file\nTo use the template, in the listing part of the document, instead of type: default declare template: path\\to\\custom_listing_declaration.ejs"
  },
  {
    "objectID": "posts/tips_quarto/quarto_howto.html#merging-python-and-observable",
    "href": "posts/tips_quarto/quarto_howto.html#merging-python-and-observable",
    "title": "Quarto how-to",
    "section": "Merging Python and Observable",
    "text": "Merging Python and Observable\nHow to merge various engines in one notebook: https://gist.github.com/hrbrmstr/23355194d1964688596553a0e6a0050a\nThe secret is to declare the language in code such as:\n\nprint('Hello python')\n# bla = {'x_values': [0,1,2,3,4], 'y_values': [10,11,12,10,9]}\nbla0 = {'x_values': [0,1,2,3,4], 'y_values': [10,11,12,10,9]}\nbla = []\nfor i in range(len(bla0['x_values'])):\n  tmp = {}\n  for k in bla0.keys():\n    tmp[k] = bla0[k][i]\n  bla.append(tmp)\nojs_define(bla=bla)\nprint(bla)\n\nHello python\n\n\n\n\n\n[{'x_values': 0, 'y_values': 10}, {'x_values': 1, 'y_values': 11}, {'x_values': 2, 'y_values': 12}, {'x_values': 3, 'y_values': 10}, {'x_values': 4, 'y_values': 9}]\n\n\n\nbla\n\n\n\n\n\n\n\nconsole.log('hello observable js')\n\n\n\n\n\n\n\nPlot.dot(bla, {x: \"x_values\", y: \"y_values\"}).plot()"
  },
  {
    "objectID": "posts/tips_quarto/quarto_links.html",
    "href": "posts/tips_quarto/quarto_links.html",
    "title": "Various resources about quarto",
    "section": "",
    "text": "Various resources on quarto\nPorting a distill blog to quarto\nThe ultimate guide to starting a Quarto blog\nHow to style your Quarto blog without knowing a lot of HTML/CSS\nGet started with Quarto: RConf2022\nAwesome Quarto"
  },
  {
    "objectID": "posts/tips_quarto/quarto_worktree.html",
    "href": "posts/tips_quarto/quarto_worktree.html",
    "title": "Fix the quarto publish gh-pages error on windows",
    "section": "",
    "text": "Sometimes quarto publish gh-pages hangs while creating the worktree.\nFor me the following worked (suggested by this tutorial and the commands quarto publish uses ).\nFirst notice the extra directory in your git repository, called 2054a64 or similar.\nThen do:\ncd 2054a64 \ngit add -Af . \ngit commit --allow-empty -m \"Semi-manual deploy\"\ngit remote -v\ngit push --force origin HEAD:gh-pages\ncd ..\ngit worktree remove 2054a64 \ngit worktree prune"
  }
]